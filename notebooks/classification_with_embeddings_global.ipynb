{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37246bcb-1f11-43e4-af11-f04500ebee20",
   "metadata": {},
   "source": [
    "## Classification based on global embeddings extracted previously using pretrained ResNest101 and Inceptionv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166a5650-bc9f-4779-a154-e88f9ac9ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim \n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36454a5-69a3-4c11-bd3b-9ce294ec240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = '../Global_embeddings'\n",
    "batch_size = 32\n",
    "epochs = 150\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "weight_decay = 3e-3\n",
    "grad_clip = 5.\n",
    "seed = 0\n",
    "use_cuda = False\n",
    "experiment='../experiment'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb96d7-2580-4f0d-b7ab-8f83651c2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and labels\n",
    "features_train = torch.load(os.path.join(load_dir, \"birds_features_train.pt\"), map_location=torch.device(device))\n",
    "labels_train = torch.load(os.path.join(load_dir, \"birds_labels_train.pt\"), map_location=torch.device(device))\n",
    "\n",
    "features_val = torch.load(os.path.join(load_dir, \"birds_features_val.pt\"), map_location=torch.device(device))\n",
    "labels_val = torch.load(os.path.join(load_dir, \"birds_labels_val.pt\"), map_location=torch.device(device))\n",
    "\n",
    "# Dataloaders\n",
    "features_tensor = torch.stack([i for i in features_train])\n",
    "labels_tensor = torch.stack([i for i in labels_train])\n",
    "train_data = torch.utils.data.TensorDataset(features_tensor, labels_tensor) \n",
    "\n",
    "features_tensor = torch.stack([torch.Tensor(i) for i in features_val])\n",
    "labels_tensor = torch.stack([i for i in labels_val])\n",
    "val_data = torch.utils.data.TensorDataset(features_tensor,labels_tensor)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ba24ef-92f4-4c28-a276-29434eee13bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self,embedding_dim):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(embedding_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = Classifier(features_train[0].shape[0])\n",
    "\n",
    "if use_cuda:\n",
    "    print('Using GPU')\n",
    "    model.cuda()\n",
    "else:\n",
    "    print('Using CPU')\n",
    "\n",
    "# Optimizer, LR, and criterion\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "# Training functions\n",
    "def train_classifier(model, train_loader, optimizer, lr_scheduler, criterion, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda().long())\n",
    "                \n",
    "        else:\n",
    "              data, target = Variable(data), Variable(target.long())\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "\n",
    "def validation_classifier(model, criterion, val_loader):\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            if use_cuda:\n",
    "                data, target = Variable(data.cuda()), Variable(target.cuda().long())\n",
    "            else:\n",
    "                data, target = Variable(data), Variable(target.long())\n",
    "            output = model(data)\n",
    "                    \n",
    "            # sum up batch loss\n",
    "            validation_loss += criterion(output, target).data.item()\n",
    "            \n",
    "            # get the index of the max log-probability\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        validation_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))\n",
    "    return(100. * correct / len(val_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b891a-9e47-44c6-8676-63bf8b687bb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training the classifier \n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_classifier(model, train_loader, optimizer, lr_scheduler, criterion, epoch)\n",
    "    val_acc=validation_classifier(model, criterion, val_loader)\n",
    "    if val_acc>=93:\n",
    "        model_file = experiment + '/model_Inceptionv3_' + str(epoch) + '.pth'\n",
    "        torch.save(model.state_dict(), model_file)\n",
    "        print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
