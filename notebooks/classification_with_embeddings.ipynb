{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37246bcb-1f11-43e4-af11-f04500ebee20",
   "metadata": {},
   "source": [
    "## Start model training:\n",
    "\n",
    "- Simple classifier that uses cropped images from detectron2\n",
    "- Even the images that are not cropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e36454a5-69a3-4c11-bd3b-9ce294ec240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim \n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from torch.utils.data import ConcatDataset, SubsetRandomSampler, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "load_dir = '../Global_embeddings'\n",
    "#load_dir_resnext = '../ResNext_embeddings'\n",
    "\n",
    "#data = \"../cropped_bird_dataset\"\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-3\n",
    "grad_clip = 5.\n",
    "seed = 0\n",
    "k_folds = 5\n",
    "experiment='../experiment'\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Features and labels of Inception v3\n",
    "features_train = torch.load(os.path.join(load_dir, \"birds_features_train.pt\"), map_location=torch.device(device))\n",
    "labels_train = torch.load(os.path.join(load_dir, \"birds_labels_train.pt\"), map_location=torch.device(device))\n",
    "\n",
    "features_val = torch.load(os.path.join(load_dir, \"birds_features_val.pt\"), map_location=torch.device(device))\n",
    "labels_val = torch.load(os.path.join(load_dir, \"birds_labels_val.pt\"), map_location=torch.device(device))\n",
    "\n",
    "# Dataloaders\n",
    "features_tensor = torch.stack([i for i in features_train])\n",
    "labels_tensor = torch.stack([i for i in labels_train])\n",
    "train_data = torch.utils.data.TensorDataset(features_tensor, labels_tensor) \n",
    "\n",
    "features_tensor = torch.stack([torch.Tensor(i) for i in features_val])\n",
    "labels_tensor = torch.stack([i for i in labels_val])\n",
    "val_data = torch.utils.data.TensorDataset(features_tensor,labels_tensor)\n",
    "\n",
    "dataset = ConcatDataset([train_data, val_data])\n",
    "\n",
    "\n",
    "# Features and labels of ResNext\n",
    "#features_train = torch.load(os.path.join(load_dir_resnext, \"birds_features_train.pt\"), map_location=torch.device(device))\n",
    "#labels_train = torch.load(os.path.join(load_dir_resnext, \"birds_labels_train.pt\"), map_location=torch.device(device))\n",
    "\n",
    "#features_val = torch.load(os.path.join(load_dir_resnext, \"birds_features_val.pt\"), map_location=torch.device(device))\n",
    "#labels_val = torch.load(os.path.join(load_dir_resnext, \"birds_labels_val.pt\"), map_location=torch.device(device))\n",
    "\n",
    "# Dataloaders\n",
    "#features_tensor = torch.stack([i for i in features_train])\n",
    "#labels_tensor = torch.stack([i for i in labels_train])\n",
    "#train_data = torch.utils.data.TensorDataset(features_tensor, labels_tensor) \n",
    "\n",
    "#features_tensor = torch.stack([torch.Tensor(i) for i in features_val])\n",
    "#labels_tensor = torch.stack([i for i in labels_val])\n",
    "#val_data = torch.utils.data.TensorDataset(features_tensor,labels_tensor)\n",
    "\n",
    "#dataset_res = ConcatDataset([train_data, val_data])\n",
    "\n",
    "# concatenate both datasets\n",
    "#dataset = ConcatDataset([dataset_inc, dataset_res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe76187-c75e-4680-953b-d9f5f5a4efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self,embedding_dim):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(embedding_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a187f2-1a06-4de4-a888-4cb902daa602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, device, dataloader, loss_fn, optimizer, lr_scheduler):\n",
    "    train_loss, train_correct = 0.0, 0\n",
    "    model.train()\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        #lr_scheduler.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        m = nn.Softmax(dim=1)\n",
    "        probs = m(output)\n",
    "        preds_classes = probs.max(1, keepdim=True)[1]\n",
    "        train_correct += preds_classes.eq(labels.data.view_as(preds_classes)).sum()\n",
    "            \n",
    "            \n",
    "        #scores, predictions = torch.max(output.data, 1)\n",
    "        #train_correct += (predictions == labels).sum().item()\n",
    "    \n",
    "    return train_loss, train_correct\n",
    "\n",
    "\n",
    "def valid_epoch(model, device, dataloader, loss_fn):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    model.eval()\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        output = model(images)\n",
    "        loss = loss_fn(output, labels)\n",
    "        valid_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        m = nn.Softmax(dim=1)\n",
    "        probs = m(output)\n",
    "        preds_classes = probs.max(1, keepdim=True)[1]\n",
    "        val_correct += preds_classes.eq(labels.data.view_as(preds_classes)).sum()\n",
    "        \n",
    "        \n",
    "        #scores, predictions = torch.max(output.data, 1)\n",
    "        #val_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    return valid_loss, val_correct\n",
    "\n",
    "def reset_weights(model):\n",
    "    \"\"\"\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "    \"\"\"\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, \"reset_parameters\"):\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e743f20f-716c-4569-88bc-be451fcea016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################\n",
      "Fold 1\n",
      "Epoch:1/50 AVG Training Loss:2.888 AVG Test Loss:2.640 AVG Training Acc 25.42 % AVG Test Acc 45.15 %\n",
      "Epoch:2/50 AVG Training Loss:2.041 AVG Test Loss:1.300 AVG Training Acc 50.11 % AVG Test Acc 62.03 %\n",
      "Epoch:3/50 AVG Training Loss:1.027 AVG Test Loss:0.888 AVG Training Acc 66.67 % AVG Test Acc 69.62 %\n",
      "Epoch:4/50 AVG Training Loss:0.631 AVG Test Loss:0.589 AVG Training Acc 77.64 % AVG Test Acc 79.32 %\n",
      "Epoch:5/50 AVG Training Loss:0.487 AVG Test Loss:0.553 AVG Training Acc 83.54 % AVG Test Acc 80.59 %\n",
      "Epoch:6/50 AVG Training Loss:0.405 AVG Test Loss:0.505 AVG Training Acc 85.55 % AVG Test Acc 82.70 %\n",
      "Epoch:7/50 AVG Training Loss:0.291 AVG Test Loss:0.418 AVG Training Acc 90.82 % AVG Test Acc 84.39 %\n",
      "Epoch     8: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Epoch:8/50 AVG Training Loss:0.252 AVG Test Loss:0.451 AVG Training Acc 90.61 % AVG Test Acc 85.23 %\n",
      "Epoch:9/50 AVG Training Loss:0.210 AVG Test Loss:0.409 AVG Training Acc 93.14 % AVG Test Acc 86.50 %\n",
      "Epoch    10: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Epoch:10/50 AVG Training Loss:0.189 AVG Test Loss:0.438 AVG Training Acc 94.20 % AVG Test Acc 84.39 %\n",
      "Epoch:11/50 AVG Training Loss:0.160 AVG Test Loss:0.380 AVG Training Acc 95.36 % AVG Test Acc 85.65 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.2500e-03.\n",
      "Epoch:12/50 AVG Training Loss:0.144 AVG Test Loss:0.384 AVG Training Acc 96.10 % AVG Test Acc 86.50 %\n",
      "Epoch:13/50 AVG Training Loss:0.138 AVG Test Loss:0.379 AVG Training Acc 95.99 % AVG Test Acc 86.92 %\n",
      "Epoch:14/50 AVG Training Loss:0.136 AVG Test Loss:0.369 AVG Training Acc 96.20 % AVG Test Acc 87.34 %\n",
      "Epoch:15/50 AVG Training Loss:0.132 AVG Test Loss:0.367 AVG Training Acc 96.62 % AVG Test Acc 88.19 %\n",
      "Epoch    16: reducing learning rate of group 0 to 6.2500e-04.\n",
      "Epoch:16/50 AVG Training Loss:0.128 AVG Test Loss:0.374 AVG Training Acc 96.84 % AVG Test Acc 87.34 %\n",
      "Epoch    17: reducing learning rate of group 0 to 3.1250e-04.\n",
      "Epoch:17/50 AVG Training Loss:0.125 AVG Test Loss:0.367 AVG Training Acc 96.62 % AVG Test Acc 86.92 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.5625e-04.\n",
      "Epoch:18/50 AVG Training Loss:0.123 AVG Test Loss:0.372 AVG Training Acc 96.62 % AVG Test Acc 86.92 %\n",
      "Epoch    19: reducing learning rate of group 0 to 7.8125e-05.\n",
      "Epoch:19/50 AVG Training Loss:0.121 AVG Test Loss:0.369 AVG Training Acc 96.73 % AVG Test Acc 87.34 %\n",
      "Epoch    20: reducing learning rate of group 0 to 3.9063e-05.\n",
      "Epoch:20/50 AVG Training Loss:0.120 AVG Test Loss:0.369 AVG Training Acc 96.84 % AVG Test Acc 86.92 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.9531e-05.\n",
      "Epoch:21/50 AVG Training Loss:0.120 AVG Test Loss:0.369 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch    22: reducing learning rate of group 0 to 9.7656e-06.\n",
      "Epoch:22/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch    23: reducing learning rate of group 0 to 4.8828e-06.\n",
      "Epoch:23/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch    24: reducing learning rate of group 0 to 2.4414e-06.\n",
      "Epoch:24/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.2207e-06.\n",
      "Epoch:25/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch    26: reducing learning rate of group 0 to 6.1035e-07.\n",
      "Epoch:26/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch    27: reducing learning rate of group 0 to 3.0518e-07.\n",
      "Epoch:27/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.5259e-07.\n",
      "Epoch:28/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch    29: reducing learning rate of group 0 to 7.6294e-08.\n",
      "Epoch:29/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch    30: reducing learning rate of group 0 to 3.8147e-08.\n",
      "Epoch:30/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.9073e-08.\n",
      "Epoch:31/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:32/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:33/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:34/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:35/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:36/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:37/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:38/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:39/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:40/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:41/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:42/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:43/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:44/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:45/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:46/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:47/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:48/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:49/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch:50/50 AVG Training Loss:0.119 AVG Test Loss:0.370 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "save model at ../experiment/classifier_fold_0.pt\n",
      "##############################################\n",
      "Fold 2\n",
      "Epoch:1/50 AVG Training Loss:2.893 AVG Test Loss:2.663 AVG Training Acc 25.21 % AVG Test Acc 53.16 %\n",
      "Epoch:2/50 AVG Training Loss:2.056 AVG Test Loss:1.450 AVG Training Acc 55.06 % AVG Test Acc 54.85 %\n",
      "Epoch:3/50 AVG Training Loss:0.971 AVG Test Loss:0.726 AVG Training Acc 70.25 % AVG Test Acc 77.22 %\n",
      "Epoch:4/50 AVG Training Loss:0.632 AVG Test Loss:0.662 AVG Training Acc 79.11 % AVG Test Acc 78.06 %\n",
      "Epoch:5/50 AVG Training Loss:0.528 AVG Test Loss:0.595 AVG Training Acc 82.28 % AVG Test Acc 79.75 %\n",
      "Epoch:6/50 AVG Training Loss:0.441 AVG Test Loss:0.516 AVG Training Acc 85.23 % AVG Test Acc 82.70 %\n",
      "Epoch:7/50 AVG Training Loss:0.347 AVG Test Loss:0.394 AVG Training Acc 87.45 % AVG Test Acc 85.23 %\n",
      "Epoch     8: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Epoch:8/50 AVG Training Loss:0.260 AVG Test Loss:0.417 AVG Training Acc 91.14 % AVG Test Acc 84.39 %\n",
      "Epoch:9/50 AVG Training Loss:0.202 AVG Test Loss:0.327 AVG Training Acc 94.09 % AVG Test Acc 89.87 %\n",
      "Epoch    10: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Epoch:10/50 AVG Training Loss:0.179 AVG Test Loss:0.340 AVG Training Acc 94.62 % AVG Test Acc 86.08 %\n",
      "Epoch:11/50 AVG Training Loss:0.161 AVG Test Loss:0.310 AVG Training Acc 94.94 % AVG Test Acc 90.30 %\n",
      "save model at ../experiment/classifier_fold_1_epoch_10.pt\n",
      "Epoch    12: reducing learning rate of group 0 to 1.2500e-03.\n",
      "Epoch:12/50 AVG Training Loss:0.153 AVG Test Loss:0.316 AVG Training Acc 95.57 % AVG Test Acc 89.45 %\n",
      "Epoch    13: reducing learning rate of group 0 to 6.2500e-04.\n",
      "Epoch:13/50 AVG Training Loss:0.142 AVG Test Loss:0.317 AVG Training Acc 96.41 % AVG Test Acc 89.87 %\n",
      "Epoch    14: reducing learning rate of group 0 to 3.1250e-04.\n",
      "Epoch:14/50 AVG Training Loss:0.135 AVG Test Loss:0.317 AVG Training Acc 96.94 % AVG Test Acc 87.76 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.5625e-04.\n",
      "Epoch:15/50 AVG Training Loss:0.133 AVG Test Loss:0.314 AVG Training Acc 96.73 % AVG Test Acc 89.45 %\n",
      "Epoch    16: reducing learning rate of group 0 to 7.8125e-05.\n",
      "Epoch:16/50 AVG Training Loss:0.131 AVG Test Loss:0.315 AVG Training Acc 96.94 % AVG Test Acc 89.45 %\n",
      "Epoch    17: reducing learning rate of group 0 to 3.9063e-05.\n",
      "Epoch:17/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.15 % AVG Test Acc 89.45 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.9531e-05.\n",
      "Epoch:18/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch    19: reducing learning rate of group 0 to 9.7656e-06.\n",
      "Epoch:19/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch    20: reducing learning rate of group 0 to 4.8828e-06.\n",
      "Epoch:20/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch    21: reducing learning rate of group 0 to 2.4414e-06.\n",
      "Epoch:21/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.2207e-06.\n",
      "Epoch:22/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch    23: reducing learning rate of group 0 to 6.1035e-07.\n",
      "Epoch:23/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch    24: reducing learning rate of group 0 to 3.0518e-07.\n",
      "Epoch:24/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.5259e-07.\n",
      "Epoch:25/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch    26: reducing learning rate of group 0 to 7.6294e-08.\n",
      "Epoch:26/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch    27: reducing learning rate of group 0 to 3.8147e-08.\n",
      "Epoch:27/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.9073e-08.\n",
      "Epoch:28/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:29/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:30/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:31/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:32/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:33/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:34/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:35/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:36/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:37/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:38/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:39/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:40/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:41/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:42/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:43/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:44/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:45/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:46/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:47/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:48/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:49/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "Epoch:50/50 AVG Training Loss:0.130 AVG Test Loss:0.314 AVG Training Acc 97.05 % AVG Test Acc 89.45 %\n",
      "save model at ../experiment/classifier_fold_1.pt\n",
      "##############################################\n",
      "Fold 3\n",
      "Epoch:1/50 AVG Training Loss:2.886 AVG Test Loss:2.633 AVG Training Acc 20.36 % AVG Test Acc 45.99 %\n",
      "Epoch:2/50 AVG Training Loss:2.072 AVG Test Loss:1.403 AVG Training Acc 53.59 % AVG Test Acc 56.12 %\n",
      "Epoch:3/50 AVG Training Loss:0.999 AVG Test Loss:0.612 AVG Training Acc 67.93 % AVG Test Acc 83.54 %\n",
      "Epoch:4/50 AVG Training Loss:0.636 AVG Test Loss:0.581 AVG Training Acc 78.48 % AVG Test Acc 80.17 %\n",
      "Epoch:5/50 AVG Training Loss:0.484 AVG Test Loss:0.507 AVG Training Acc 83.33 % AVG Test Acc 81.01 %\n",
      "Epoch     6: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Epoch:6/50 AVG Training Loss:0.413 AVG Test Loss:0.605 AVG Training Acc 85.02 % AVG Test Acc 79.32 %\n",
      "Epoch:7/50 AVG Training Loss:0.335 AVG Test Loss:0.369 AVG Training Acc 89.03 % AVG Test Acc 88.19 %\n",
      "Epoch:8/50 AVG Training Loss:0.255 AVG Test Loss:0.349 AVG Training Acc 91.98 % AVG Test Acc 87.34 %\n",
      "Epoch     9: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Epoch:9/50 AVG Training Loss:0.232 AVG Test Loss:0.400 AVG Training Acc 92.19 % AVG Test Acc 84.81 %\n",
      "Epoch:10/50 AVG Training Loss:0.216 AVG Test Loss:0.344 AVG Training Acc 91.98 % AVG Test Acc 87.34 %\n",
      "Epoch:11/50 AVG Training Loss:0.197 AVG Test Loss:0.343 AVG Training Acc 93.78 % AVG Test Acc 88.19 %\n",
      "Epoch:12/50 AVG Training Loss:0.187 AVG Test Loss:0.328 AVG Training Acc 93.88 % AVG Test Acc 87.34 %\n",
      "Epoch    13: reducing learning rate of group 0 to 1.2500e-03.\n",
      "Epoch:13/50 AVG Training Loss:0.174 AVG Test Loss:0.341 AVG Training Acc 94.94 % AVG Test Acc 87.76 %\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-04.\n",
      "Epoch:14/50 AVG Training Loss:0.163 AVG Test Loss:0.332 AVG Training Acc 95.04 % AVG Test Acc 87.76 %\n",
      "Epoch    15: reducing learning rate of group 0 to 3.1250e-04.\n",
      "Epoch:15/50 AVG Training Loss:0.162 AVG Test Loss:0.331 AVG Training Acc 95.36 % AVG Test Acc 88.19 %\n",
      "Epoch:16/50 AVG Training Loss:0.153 AVG Test Loss:0.328 AVG Training Acc 95.89 % AVG Test Acc 87.76 %\n",
      "Epoch:17/50 AVG Training Loss:0.151 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 88.19 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.5625e-04.\n",
      "Epoch:18/50 AVG Training Loss:0.150 AVG Test Loss:0.326 AVG Training Acc 95.99 % AVG Test Acc 87.76 %\n",
      "Epoch:19/50 AVG Training Loss:0.148 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch    20: reducing learning rate of group 0 to 7.8125e-05.\n",
      "Epoch:20/50 AVG Training Loss:0.148 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 88.19 %\n",
      "Epoch    21: reducing learning rate of group 0 to 3.9063e-05.\n",
      "Epoch:21/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.20 % AVG Test Acc 87.76 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.9531e-05.\n",
      "Epoch:22/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.31 % AVG Test Acc 88.19 %\n",
      "Epoch    23: reducing learning rate of group 0 to 9.7656e-06.\n",
      "Epoch:23/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch    24: reducing learning rate of group 0 to 4.8828e-06.\n",
      "Epoch:24/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch    25: reducing learning rate of group 0 to 2.4414e-06.\n",
      "Epoch:25/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.2207e-06.\n",
      "Epoch:26/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch    27: reducing learning rate of group 0 to 6.1035e-07.\n",
      "Epoch:27/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch    28: reducing learning rate of group 0 to 3.0518e-07.\n",
      "Epoch:28/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.5259e-07.\n",
      "Epoch:29/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch    30: reducing learning rate of group 0 to 7.6294e-08.\n",
      "Epoch:30/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch    31: reducing learning rate of group 0 to 3.8147e-08.\n",
      "Epoch:31/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.9073e-08.\n",
      "Epoch:32/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:33/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:34/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:35/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:36/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:37/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:38/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:39/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:40/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:41/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:42/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:43/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:44/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:45/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:46/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:47/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:48/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:49/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "Epoch:50/50 AVG Training Loss:0.147 AVG Test Loss:0.326 AVG Training Acc 96.10 % AVG Test Acc 87.76 %\n",
      "save model at ../experiment/classifier_fold_2.pt\n",
      "##############################################\n",
      "Fold 4\n",
      "Epoch:1/50 AVG Training Loss:2.890 AVG Test Loss:2.636 AVG Training Acc 21.41 % AVG Test Acc 45.57 %\n",
      "Epoch:2/50 AVG Training Loss:2.037 AVG Test Loss:1.381 AVG Training Acc 50.63 % AVG Test Acc 58.23 %\n",
      "Epoch:3/50 AVG Training Loss:0.986 AVG Test Loss:0.782 AVG Training Acc 69.20 % AVG Test Acc 73.00 %\n",
      "Epoch:4/50 AVG Training Loss:0.683 AVG Test Loss:0.621 AVG Training Acc 77.32 % AVG Test Acc 79.32 %\n",
      "Epoch:5/50 AVG Training Loss:0.497 AVG Test Loss:0.523 AVG Training Acc 83.65 % AVG Test Acc 81.01 %\n",
      "Epoch     6: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Epoch:6/50 AVG Training Loss:0.407 AVG Test Loss:0.545 AVG Training Acc 85.65 % AVG Test Acc 81.43 %\n",
      "Epoch:7/50 AVG Training Loss:0.300 AVG Test Loss:0.446 AVG Training Acc 90.30 % AVG Test Acc 85.23 %\n",
      "Epoch:8/50 AVG Training Loss:0.273 AVG Test Loss:0.443 AVG Training Acc 91.46 % AVG Test Acc 83.97 %\n",
      "Epoch:9/50 AVG Training Loss:0.246 AVG Test Loss:0.391 AVG Training Acc 91.67 % AVG Test Acc 88.61 %\n",
      "Epoch:10/50 AVG Training Loss:0.226 AVG Test Loss:0.388 AVG Training Acc 93.14 % AVG Test Acc 85.65 %\n",
      "Epoch    11: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Epoch:11/50 AVG Training Loss:0.207 AVG Test Loss:0.426 AVG Training Acc 93.35 % AVG Test Acc 84.81 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.2500e-03.\n",
      "Epoch:12/50 AVG Training Loss:0.181 AVG Test Loss:0.392 AVG Training Acc 94.73 % AVG Test Acc 86.50 %\n",
      "Epoch:13/50 AVG Training Loss:0.168 AVG Test Loss:0.371 AVG Training Acc 95.89 % AVG Test Acc 87.34 %\n",
      "Epoch:14/50 AVG Training Loss:0.156 AVG Test Loss:0.367 AVG Training Acc 95.57 % AVG Test Acc 85.65 %\n",
      "Epoch:15/50 AVG Training Loss:0.153 AVG Test Loss:0.359 AVG Training Acc 95.78 % AVG Test Acc 87.76 %\n",
      "Epoch    16: reducing learning rate of group 0 to 6.2500e-04.\n",
      "Epoch:16/50 AVG Training Loss:0.150 AVG Test Loss:0.360 AVG Training Acc 96.20 % AVG Test Acc 86.50 %\n",
      "Epoch    17: reducing learning rate of group 0 to 3.1250e-04.\n",
      "Epoch:17/50 AVG Training Loss:0.144 AVG Test Loss:0.361 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.5625e-04.\n",
      "Epoch:18/50 AVG Training Loss:0.142 AVG Test Loss:0.361 AVG Training Acc 96.73 % AVG Test Acc 86.92 %\n",
      "Epoch    19: reducing learning rate of group 0 to 7.8125e-05.\n",
      "Epoch:19/50 AVG Training Loss:0.140 AVG Test Loss:0.360 AVG Training Acc 97.05 % AVG Test Acc 86.50 %\n",
      "Epoch    20: reducing learning rate of group 0 to 3.9063e-05.\n",
      "Epoch:20/50 AVG Training Loss:0.139 AVG Test Loss:0.361 AVG Training Acc 96.94 % AVG Test Acc 86.08 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.9531e-05.\n",
      "Epoch:21/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch    22: reducing learning rate of group 0 to 9.7656e-06.\n",
      "Epoch:22/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch    23: reducing learning rate of group 0 to 4.8828e-06.\n",
      "Epoch:23/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch    24: reducing learning rate of group 0 to 2.4414e-06.\n",
      "Epoch:24/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.2207e-06.\n",
      "Epoch:25/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch    26: reducing learning rate of group 0 to 6.1035e-07.\n",
      "Epoch:26/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch    27: reducing learning rate of group 0 to 3.0518e-07.\n",
      "Epoch:27/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.5259e-07.\n",
      "Epoch:28/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch    29: reducing learning rate of group 0 to 7.6294e-08.\n",
      "Epoch:29/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch    30: reducing learning rate of group 0 to 3.8147e-08.\n",
      "Epoch:30/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.9073e-08.\n",
      "Epoch:31/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:32/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:33/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:34/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:35/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:36/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:37/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:38/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:39/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:40/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:41/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:42/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:43/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:44/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:45/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:46/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:47/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:48/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:49/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "Epoch:50/50 AVG Training Loss:0.139 AVG Test Loss:0.360 AVG Training Acc 96.94 % AVG Test Acc 86.50 %\n",
      "save model at ../experiment/classifier_fold_3.pt\n",
      "##############################################\n",
      "Fold 5\n",
      "Epoch:1/50 AVG Training Loss:2.893 AVG Test Loss:2.667 AVG Training Acc 24.26 % AVG Test Acc 34.18 %\n",
      "Epoch:2/50 AVG Training Loss:2.045 AVG Test Loss:1.390 AVG Training Acc 54.54 % AVG Test Acc 60.34 %\n",
      "Epoch:3/50 AVG Training Loss:0.954 AVG Test Loss:0.838 AVG Training Acc 70.04 % AVG Test Acc 71.73 %\n",
      "Epoch:4/50 AVG Training Loss:0.609 AVG Test Loss:0.813 AVG Training Acc 79.22 % AVG Test Acc 71.31 %\n",
      "Epoch:5/50 AVG Training Loss:0.525 AVG Test Loss:0.650 AVG Training Acc 83.02 % AVG Test Acc 77.22 %\n",
      "Epoch     6: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Epoch:6/50 AVG Training Loss:0.390 AVG Test Loss:0.663 AVG Training Acc 86.60 % AVG Test Acc 76.37 %\n",
      "Epoch:7/50 AVG Training Loss:0.315 AVG Test Loss:0.486 AVG Training Acc 89.24 % AVG Test Acc 80.59 %\n",
      "Epoch:8/50 AVG Training Loss:0.260 AVG Test Loss:0.460 AVG Training Acc 91.88 % AVG Test Acc 82.70 %\n",
      "Epoch     9: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Epoch:9/50 AVG Training Loss:0.223 AVG Test Loss:0.500 AVG Training Acc 93.88 % AVG Test Acc 81.86 %\n",
      "Epoch:10/50 AVG Training Loss:0.194 AVG Test Loss:0.435 AVG Training Acc 94.83 % AVG Test Acc 84.39 %\n",
      "Epoch:11/50 AVG Training Loss:0.185 AVG Test Loss:0.431 AVG Training Acc 94.30 % AVG Test Acc 84.39 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.2500e-03.\n",
      "Epoch:12/50 AVG Training Loss:0.178 AVG Test Loss:0.436 AVG Training Acc 95.25 % AVG Test Acc 84.81 %\n",
      "Epoch:13/50 AVG Training Loss:0.163 AVG Test Loss:0.424 AVG Training Acc 95.36 % AVG Test Acc 83.12 %\n",
      "Epoch:14/50 AVG Training Loss:0.159 AVG Test Loss:0.419 AVG Training Acc 95.89 % AVG Test Acc 83.97 %\n",
      "Epoch    15: reducing learning rate of group 0 to 6.2500e-04.\n",
      "Epoch:15/50 AVG Training Loss:0.159 AVG Test Loss:0.434 AVG Training Acc 95.68 % AVG Test Acc 85.65 %\n",
      "Epoch    16: reducing learning rate of group 0 to 3.1250e-04.\n",
      "Epoch:16/50 AVG Training Loss:0.154 AVG Test Loss:0.425 AVG Training Acc 96.20 % AVG Test Acc 83.97 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.5625e-04.\n",
      "Epoch:17/50 AVG Training Loss:0.147 AVG Test Loss:0.423 AVG Training Acc 95.99 % AVG Test Acc 84.39 %\n",
      "Epoch    18: reducing learning rate of group 0 to 7.8125e-05.\n",
      "Epoch:18/50 AVG Training Loss:0.146 AVG Test Loss:0.423 AVG Training Acc 96.10 % AVG Test Acc 83.97 %\n",
      "Epoch    19: reducing learning rate of group 0 to 3.9063e-05.\n",
      "Epoch:19/50 AVG Training Loss:0.145 AVG Test Loss:0.422 AVG Training Acc 96.10 % AVG Test Acc 84.39 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.9531e-05.\n",
      "Epoch:20/50 AVG Training Loss:0.145 AVG Test Loss:0.422 AVG Training Acc 96.10 % AVG Test Acc 84.39 %\n",
      "Epoch    21: reducing learning rate of group 0 to 9.7656e-06.\n",
      "Epoch:21/50 AVG Training Loss:0.144 AVG Test Loss:0.422 AVG Training Acc 96.10 % AVG Test Acc 84.39 %\n",
      "Epoch    22: reducing learning rate of group 0 to 4.8828e-06.\n",
      "Epoch:22/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.10 % AVG Test Acc 84.39 %\n",
      "Epoch    23: reducing learning rate of group 0 to 2.4414e-06.\n",
      "Epoch:23/50 AVG Training Loss:0.144 AVG Test Loss:0.422 AVG Training Acc 96.10 % AVG Test Acc 84.39 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.2207e-06.\n",
      "Epoch:24/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.10 % AVG Test Acc 84.39 %\n",
      "Epoch    25: reducing learning rate of group 0 to 6.1035e-07.\n",
      "Epoch:25/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch    26: reducing learning rate of group 0 to 3.0518e-07.\n",
      "Epoch:26/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.5259e-07.\n",
      "Epoch:27/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch    28: reducing learning rate of group 0 to 7.6294e-08.\n",
      "Epoch:28/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch    29: reducing learning rate of group 0 to 3.8147e-08.\n",
      "Epoch:29/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.9073e-08.\n",
      "Epoch:30/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:31/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:32/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:33/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:34/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:35/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:36/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:37/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:38/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:39/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:40/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:41/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:42/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:43/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:44/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:45/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:46/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:47/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:48/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:49/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "Epoch:50/50 AVG Training Loss:0.144 AVG Test Loss:0.423 AVG Training Acc 96.20 % AVG Test Acc 84.39 %\n",
      "save model at ../experiment/classifier_fold_4.pt\n",
      "Performance of 5 fold cross validation\n",
      "Average Training Loss: 0.281 \t Average Test Loss: 0.452 \t Average Training Acc: 92.35 \t Average Test Acc: 84.76\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAHwCAYAAAAIDnN0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8DElEQVR4nO3deXzcVb3/8fdnJstknSRdkrRJmrZAN+gCKbsCVTahwk9FQLjqdeGC29V7cdcrV/Re14tyXdGLeK8bgqKCiiwCBVlTLHSjUOiW7k3bSdpmnZzfH99pmjRpO5PM5DvL6/l4zOM7c2a+mU+ch+Hd8z3zOeacEwAAAPwT8LsAAACAXEcgAwAA8BmBDAAAwGcEMgAAAJ8RyAAAAHxGIAMAAPAZgQwAjsHM1pvZG/2uA0D2IpAByChm9g4zazazfWa21cz+bGZnx567ycycmb19wOvzYmONscd3xB6fOuA1x5kZTRkB+IZABiBjmNm/SPqWpP+QVC2pQdL3JF024GW7Jf27mQWP8qN2S/pSisoEgIQRyABkBDMLS/qipA86537rnNvvnOtxzt3rnPv4gJfeL6lb0rVH+XE/lTTXzM4ZQR2FZvYtM9sSu33LzApjz403s/vMbK+Z7Tazx80sEHvuk2a22czazWyNmb0h0fcGkL0IZAAyxRmSQpLuOcbrnKTPS/qCmeUf4TUH5M2yfXkEdXxW0umS5kuaJ+lUSZ+LPfevklokTZA3g/cZSc7MZkj6kKSFzrkySRdKWj+C9waQpQhkADLFOEm7nHO9x3qhc+4PknZKet9RXvZDSQ1mdnGCdVwj6YvOuR3OuZ2S/l3SP8Se65FUK2lKbPbucedtGByVVChptpnlO+fWO+deTfB9AWQxAhmATNEqabyZ5cX5+s/Jm80KDfekc65L0s2xWyImSdow4PGG2JgkfV3SWkkPmNlrZvap2HutlfRRSTdJ2mFmvzKzSQKAGAIZgEzxlKQuSZfH82Ln3IPywtEHjvKyn0iqkPSWBOrYImnKgMcNsTE559qdc//qnJsm6c2S/uXgWjHn3C+cc2fHznWSvprAewLIcgQyABnBOReR9G+Svmtml5tZsZnlm9nFZva1I5z2WUmfOMrP7JX0BUmfTKCUX0r6nJlNMLPxsZp+JklmdmmshYZJisi7VNlnZjPMbFFs8X+npA5JfQm8J4AsRyADkDGcc9+U9C/yLkfulLRJ3mL53x3h9X+T9OwxfuwvJW1NoIwvSWqW9KKk5ZKe16EWGsdLekjSPnkzet9zzj0ib/3YVyTtkrRN0kRJn07gPQFkOfPWmwIAAMAvzJABAAD4jEAGAADgMwIZAACAzwhkAAAAPiOQAQAA+Czejtdpafz48a6xsdHvMgAAAI5p6dKlu5xzE4Z7LqMDWWNjo5qbm/0uAwAA4JjMbMORnuOSJQAAgM8IZAAAAD4jkAEAAPgso9eQAQCAzNDT06OWlhZ1dnb6XUrKhUIh1dXVKT8/P+5zCGQAACDlWlpaVFZWpsbGRpmZ3+WkjHNOra2tamlp0dSpU+M+j0uWAAAg5To7OzVu3LisDmOSZGYaN25cwjOBBDIAADAmsj2MHTSS35NABgAAsl5ra6vmz5+v+fPnq6amRpMnT+5/3N3dfdRzm5ub9ZGPfCSl9bGGDAAAZL1x48Zp2bJlkqSbbrpJpaWluvHGG/uf7+3tVV7e8LGoqalJTU1NKa2PGTIAAJCT3v3ud+v666/Xaaedpk984hN69tlndcYZZ2jBggU688wztWbNGknSo48+qksvvVSSF+be85736Nxzz9W0adN06623JqUWZsgAAMCY+vd7V2rVlrak/szZk8r1hcVzEj6vpaVFTz75pILBoNra2vT4448rLy9PDz30kD7zmc/oN7/5zZBzXnrpJT3yyCNqb2/XjBkzdMMNNyTU4mI4BDIAAJCzrrjiCgWDQUlSJBLRu971Lr3yyisyM/X09Ax7ziWXXKLCwkIVFhZq4sSJ2r59u+rq6kZVB4EMAACMqZHMZKVKSUlJ//3Pf/7zOu+883TPPfdo/fr1Ovfcc4c9p7CwsP9+MBhUb2/vqOvIyDVkZrbYzG6LRCJ+lwIAALJEJBLR5MmTJUl33HHHmL53RgYy59y9zrnrwuGw36UAAIAs8YlPfEKf/vSntWDBgqTMeiXCnHNj+obJ1NTU5Jqbm/0uAwAAHMPq1as1a9Ysv8sYM8P9vma21Dk3bP+MjJwhG0vbItm/CSoAAPAXgewo7nxuo07/z4e1eW+H36UAAIAsRiA7ijmTvDVqzet3+1wJAADIZgSyo5hZU6bSwjw9RyADAAApRCA7irxgQAsaKtS8fo/fpQAAgCxGIDuGpilVWrO9XZGO4bv1AgAAjBad+o9hYWOlnJOe37hH582Y6Hc5AABgBFpbW/WGN7xBkrRt2zYFg0FNmDBBkvTss8+qoKDgqOc/+uijKigo0JlnnpmS+ghkxzC/oULBgKl5/W4CGQAAGWrcuHFatmyZJOmmm25SaWmpbrzxxrjPf/TRR1VaWpqyQMYly2MoLsjTnEnlrCMDACDLLF26VOecc45OOeUUXXjhhdq6dask6dZbb9Xs2bM1d+5cXXXVVVq/fr1+8IMf6JZbbtH8+fP1+OOPJ70WZsji0DSlSj9/ZoO6e/tUkEeGBQBgVP78KWnb8uT+zJqTpIu/EvfLnXP68Ic/rN///veaMGGC7rzzTn32s5/V7bffrq985Stat26dCgsLtXfvXlVUVOj6669PeFYtEQSyOCxsrNTtf1unFVsiOrmh0u9yAADAKHV1dWnFihU6//zzJUnRaFS1tbWSpLlz5+qaa67R5Zdfrssvv3xM6iGQxeGURi+ELV2/h0AGAMBoJTCTlSrOOc2ZM0dPPfXUkOf++Mc/asmSJbr33nv15S9/WcuXJ3k2bxhcfzuatQ9L/3OhJgb2acq4YhrEAgCQJQoLC7Vz587+QNbT06OVK1eqr69PmzZt0nnnnaevfvWrikQi2rdvn8rKytTe3p6yeghkRxPtljY9Le3ZoKYpVVq6YY+cc35XBQAARikQCOjuu+/WJz/5Sc2bN0/z58/Xk08+qWg0qmuvvVYnnXSSFixYoI985COqqKjQ4sWLdc8997Co3xfheu8Y2aiFjafoN8+3aN2u/Zo2odTfugAAwIjddNNN/feXLFky5PknnnhiyNgJJ5ygF198MWU1MUN2NBWxQLZ3o5pi68hofwEAAJKNQHY0obAUqpD2btT0CaWqLM5nHRkAAEg6AtmxVNRLezfJzHTKlCo1b2CGDAAAJBeB7Fgqpkh7N0qSmhortW7Xfu3a1+VzUQAAZJ5c+WLcSH5PAtmxhOu9QOacFrKODACAEQmFQmptbc36UOacU2trq0KhUELn8S3LY6lokHr2Sx17dOLksAryAmpev1sXnVjjd2UAAGSMuro6tbS0aOfOnX6XknKhUEh1dXUJnUMgO5aKBu+4d4MKJy3QvLow68gAAEhQfn6+pk6d6ncZaYtLlsfS3/pikySpqbFKKzZH1NEd9bEoAACQTQhkx9I/Q+Yt7F/YWKnePqdlm/b6VxMAAMgqBLJjCVVIheX9geyUhipJ0tIN9CMDAADJQSA7FjPvm5YR75JluDhfJ1SX6jm+aQkAAJKEQBaPiob+GTLJW0f2/IY9ivZl91d3AQDA2CCQxeOwQLawsVLtXb1as63dx6IAAEC2IJDFo6Je6mqTOvZKkpqmsI4MAAAkD4EsHod907KuskjV5YWsIwMAAElBIItH+GAvMi+QmZmaGqvUvJ4ZMgAAMHoEsnhUTPGOsW9aSlLTlEptiXRq894On4oCAADZgkAWj+IqKb/ksIX93joyZskAAMBoEcjiYeYt7B8QyGbWlKmkIKhm1pEBAIBRIpDF67DWF3nBgBY0VLLROAAAGDUCWbwOC2SS1NRYqZe2tamts8enogAAQDYgkMUrXC917pU62/qHFjZWyTnpeWbJAADAKBDI4nWwF9mAb1rOr69QMGCsIwMAAKNCIIvXwdYXAy5blhTmaXZtuZrp2A8AAEaBQBavioPNYTcNGm5qrNSyTXvV3dvnQ1EAACAbEMjiVTJBygtJezcMGl7YWKXOnj6t3BLxqTAAAJDpCGTxMvPWkUUOmyGbUilJWsrCfgAAMEIEskSE64e0vphYHlJDVbGeo2M/AAAYIQJZIobpRSZ568ia1++Rc86HogAAQKYjkCWiol460Cp17x803DSlSq37u7W+9YBPhQEAgExGIEtEf+uLwevIFjZ668ieW8dlSwAAkDgCWSIONoc97LLl9AmlKswL6JUd7T4UBQAAMh2BLBHhWC+yyOBAFgiYasMhbY10+lAUAADIdASyRJRWS8GCYRf214RD2kYgAwAAI5CRgczMFpvZbZHIGDdjDQSGbX0hSbXhImbIAADAiGRkIHPO3eucuy4cDo/9m1fUD1nUL3kzZNvbOtXXR+sLAACQmIwMZL46Qi+y2nBIvX1Ou/Z3+VAUAADIZASyRFU0SPt3SD0dg4ZrykOSxDoyAACQMAJZosKx1heRlkHDteEiSWIdGQAASBiBLFH9vcg2DBquCTNDBgAARoZAlqiKWC+ywxb2jyspUH7QmCEDAAAJI5AlqqxWCuQNWdgfCJiqy0PaFuk4wokAAADDI5AlKhCUwnXDftNyEr3IAADACBDIRiJcL0WG70W2rY1ABgAAEkMgG4mKKUfsRbY10innaA4LAADiRyAbiYoGqX2b1Du4CWxNOKTu3j7t3t/tU2EAACATEchGoqJekhumF5nX+oJ1ZAAAIBEEspHo70U2+LJlTaw5LL3IAABAIghkI3EwkB22sL9/hoyF/QAAIAEEspEomyRZcMgM2fjSQgUDRi8yAACQEALZSATzpPLJQwJZMGCqLitkDRkAAEgIgWykKuqHbJ8kxXqREcgAAEACCGQjVdFwhF5kRQQyAACQEALZSFU0SO1bpGjPoOEamsMCAIAEEchGKlwvuT6pbfOg4dpwSB09UbV19PpUGAAAyDQEspE6Qi+y2lgvsq1tfNMSAADEh0A2Uv2BbPDC/hq69QMAgAQRyEaqfLIkG2aGzAtkLOwHAADxIpCNVF6BVD5pSCCbUFaogDFDBgAA4kcgG42KhiHbJ+UHA5pQVki3fgAAEDcC2WiE66W9G4YM14SLmCEDAABxI5CNRkWDFNksRQe3uKgtDxHIAABA3Ahko1FRL7mo1L510DDbJwEAgEQQyEbjiL3IQtrX1av2zp5hTgIAABiMQDYaFVO8Y2T4XmTMkgEAgHgQyEajfLJ3PFK3fgIZAACIA4FsNPJDUmnNkG9a0hwWAAAkgkA2WhUNQ7ZPmlheKIkZMgAAEB8C2WhV1A+5ZFmYF9T40gJtY4NxAAAQBwLZaFU0SJEWqa9v0HAtzWEBAECcCGSjVdEg9fVI+7YNGqYXGQAAiBeBbLTCR+5FxgwZAACIB4FstPqbww7tRRbp6NGB7t5hTgIAADiEQDZa4TrvSOsLAAAwQgSy0SoolkomDLlkWVNOc1gAABAfAlkyVDQM2T7p4AwZgQwAABwLgSwZwkN7kR3az5JeZAAA4OgIZMlwsFv/gF5kofygKovzmSEDAADHRCBLhooGKdol7d85aLgmXMSifgAAcEwEsmSooBcZAAAYOQJZMhwMZJGh68i2tRHIAADA0RHIkiFc7x33HNaLrDyk3fu71dkT9aEoAACQKQhkyVBYKhWPl/asHzRcW+H1ItvOLBkAADgKAlmyVE2V9qwbNEQvMgAAEA8CWbJUTh0yQ1bD9kkAACAOBLJkqZoqRVqk3u7+oZpyZsgAAMCxEciSpbJRcn2DtlAqKcxTeSiPbv0AAOCoCGTJUjnVO+4+fB1ZETNkAADgqAhkyVIVC2SHLeynFxkAADgWAlmylFZL+cXDzJCFtGUvgQwAABwZgSxZzLx1ZMPMkO3a16Xu3r7hzwMAADmPQJZMw7S+ONiLjOawAADgSAhkyVQVC2TO9Q/VhL1u/awjAwAAR0IgS6bKRqnngLRve/8Q3foBAMCxEMiSaZjWF4e69dOLDAAADI9AlkzDtL4oD+WrtDCPGTIAAHBEBLJkCtdLFhjS+qImHGI/SwAAcEQEsmTKK5DCdUNaX9SGQ8yQAQCAIyKQJVvl1KEzZOXMkAEAgCMjkCVb1fC9yHa0d6o3SnNYAAAwFIEs2SobpQO7pK72/qGacJH6nLRzX5d/dQEAgLRFIEu2YVpf0IsMAAAcDYEs2YZpfXGoFxmBDAAADEUgS7ajzJBt2UtzWAAAMBSBLNlC5VLxuEEzZOGifIXyA8yQAQCAYRHIUuGw1hdmptpwkbaywTgAABgGgSwVhml9QS8yAABwJASyVKicKkVapGhP/1At2ycBAIAjIJClQmWj5KLS3o39Q7UVIW1v61S0z/lXFwAASEsEslQYtvVFkXr7nFppDgsAAA5DIEuF4VpflNMcFgAADI9AlgplNVJe0aCF/TV06wcAAEdAIEsFM28d2TDNYbdFaA4LAAAGI5ClStXUQWvIqkoKVBAM0IsMAAAMQSBLlcpYLzLnfavSzFRD6wsAADAMAlmqVDZKPQekfTv6h2rCIdaQAQCAIQhkqTJM6wuawwIAgOEQyFJlmNYXBy9ZOkdzWAAAcAiBLFUqGiQLDJ4hKw+pO9qn1v3dPhYGAADSDYEsVfIKpPK6w2bIiiSJy5YAAGCQtAlkZlZiZj81sx+Z2TV+15MUVY1D1pBJNIcFAACDpTSQmdntZrbDzFYcNn6Rma0xs7Vm9qnY8Fsk3e2ce7+kN6eyrjFTOXVwc9gKmsMCAIChUj1DdoekiwYOmFlQ0nclXSxptqSrzWy2pDpJm2Ivi6a4rrFR2Sgd2CV1tUuSxpcUKi9gzJABAIBBUhrInHNLJO0+bPhUSWudc68557ol/UrSZZJa5IWylNc1ZvpbX6yXJAUCpupyWl8AAIDB/Ag+k3VoJkzygthkSb+V9FYz+76ke490spldZ2bNZta8c+fO1FY6WsO0vqilOSwAADhMnt8FHOSc2y/pH+N43W2SbpOkpqam9G7oNVxz2IoiLdu0x6eCAABAOvJjhmyzpPoBj+tiY9knFJaKqgbNkM2oLtWm3R1q7+zxsTAAAJBO/Ahkz0k63symmlmBpKsk/cGHOsZG1dRBM2SzasslSWu2tftVEQAASDOpbnvxS0lPSZphZi1m9l7nXK+kD0n6i6TVkn7tnFuZyjp8dVjri5mxQLZ6a5tfFQEAgDST0jVkzrmrjzD+J0l/SuV7p43KRmnlPVK0Rwrma1I4pPJQnlZtZYYMAAB4sqO9RDqrmiq5qBTxvlhqZppVW84MGQAA6EcgS7VhWl/Mqi3Xmm3t6utL7y+JAgCAsUEgS7VhWl/Mri1XR09UG3Yf8KkoAACQTghkqVZaI+WFhsyQSSzsBwAAHgJZqgUC3sL+2PZJknR8damCASOQAQAASQSysXFY64tQflDTxpcQyAAAgCQC2diomurNkLlDi/i9b1rS+gIAAGRoIDOzxWZ2WyQS8buU+FQ2Sj37pf2HNkOfVVuuzXs7FDnAFkoAAOS6jAxkzrl7nXPXhcNhv0uJz7CtL8okSau3cdkSAIBcl5GBLOMcofWFxDctAQAAgWxsVDRIskEzZBPKCjWupIBABgAACGRjIq9QCtcNmiE7tIUSC/sBAMh1BLKxUtk4aIZM8taRrdnert5onz81AQCAtEAgGytVUwfNkEneNy27e/u0btd+n4oCAADpgEA2ViobvbYXXfv6h2bWeAv7V7GODACAnEYgGysHW18M2ELpuImlyg8a68gAAMhxBLKxMkzri4K8gKZPKOWblgAA5DgC2VgZpjms5PUje4nmsAAA5DQC2VgpqpCKKodd2L+9rUu793f7UxcAAPAdgWwsVU4dpvUFHfsBAMh1BLKxNGzri9ielgQyAAByFoFsLFU2Sns3SdGe/qFxpYWaWFZI6wsAAHIYgWwsVU6VXFSKtAwaZgslAAByW0YGMjNbbGa3RSIRv0tJzDCtLyQvkK3d0a7uXrZQAgAgF2VkIHPO3eucuy4cDvtdSmKO0PpiVm2ZeqJOr+7cN8xJAAAg22VkIMtYZbVSsHDIDNlsvmkJAEBOI5CNpUDAW9h/2AzZ1PElKsgLEMgAAMhRBLKxVjVV2vmS5Fz/UF4woBnVZSzsBwAgRxHIxtrMS6TWtdLahwcNz6ot0+qtbXIDghoAAMgNBLKxNvcqKVwvPfaVQbNks2rL1bq/Wzvbu3wsDgAA+IFANtbyCqSzPya1PCe99mj/8Mwab2E/DWIBAMg9BDI/LLhWKpskLfl6/9Chb1qyjgwAgFxDIPNDXqF09kelDX+T1j8hSQoX52tSOMQ3LQEAyEEEMr+c/E6ptFp67Kv9Q7Nqy/XSNgIZAAC5hkDml/wi6cyPSOuWSBufluQFsld37ldnT9Tn4gAAwFgikPmp6R+l4vHSY1+T5AWyaJ/T2h1soQQAQC4hkPmpoEQ688PSqw9LLUs1q7ZMEt+0BAAg1xDI/LbwvVJRpbTka5oyrkRF+UEW9gMAkGMIZH4rLJPO+KD08v0KbntBM2rKCGQAAOQYAlk6OPU6KRSWlnxds2rLtXprO1soAQCQQzIykJnZYjO7LRKJ+F1KcoTC0mk3SC/dpzNLtyrS0aOtkU6/qwIAAGMkIwOZc+5e59x14XDY71KS5/TrpYIynbXlDknisiUAADkkIwNZViqqlE67TpXr/6TjrIVABgBADiGQpZPTPyjLL9Yni+9jT0sAAHIIgSydlIyTFr5Xb4g+ofbNq/2uBgAAjBECWbo588OKBvL15vZf6UB3r9/VAACAMRBXIDOzEjMLxO6fYGZvNrP81JaWo0onavO0q3R54Amte3ml39UAAIAxEO8M2RJJITObLOkBSf8g6Y5UFZXr8l/3UUUVVOHT3/a7FAAAMAbiDWTmnDsg6S2Svuecu0LSnNSVldtq66fqbr1BU1t+J+1Z73c5AAAgxeIOZGZ2hqRrJP0xNhZMTUkIBEyPTbhGvcqTHr7Z73IAAECKxRvIPirp05Lucc6tNLNpkh5JWVVQdd003eEukVbcLbUs9bscAACQQnEFMufcY865Nzvnvhpb3L/LOfeRFNeW02bVluvWrksULRovPfA5ib0tAQDIWvF+y/IXZlZuZiWSVkhaZWYfT21pue3UqVXaryI903i9tPFJ6aU/HvskAACQkeK9ZDnbOdcm6XJJf5Y0Vd43LZEix00s1cyaMt3Sero0fob04L9J0R6/ywIAACkQbyDLj/Udu1zSH5xzPZK4hpZii+dN0nMb29R61uek3a9KzT/xuyQAAJAC8QayH0paL6lE0hIzmyKJ3a9T7NK5tZKk37bNkaa+Xnr0P6XOiM9VAQCAZIt3Uf+tzrnJzrk3Oc8GSeeluLacN2VciU6aHNZ9y7dKF3xJ6tgjPf5ffpcFAACSLN5F/WEz+y8za47dvilvtgwpduncWr3QEtHGguOluVdKT39f2rvR77IAAEASxXvJ8nZJ7ZLeHru1SWJB0xi4JHbZ8t4Xt0iLPieZ0SwWAIAsE28gm+6c+4Jz7rXY7d8lTUtlYfDUVRZrQUOF7ntxq1RRL53+AWn5r6XNz/tdGgAASJJ4A1mHmZ198IGZnSWpIzUlHZuZLTaz2yKR3FjgfuncSVq9tU2v7twnnf0xqXi89MDnaRYLAECWiDeQXS/pu2a23szWS/qOpH9KWVXH4Jy71zl3XTgc9quEMXXJSbUyk+57YasUKpfO/ZS04QlpzZ/9Lg0AACRBvN+yfME5N0/SXElznXMLJC1KaWXoVxMOaWFjle57cYs3cMq7pXHH0ywWAIAsEe8MmSTJOdcW69gvSf+SgnpwBIvn1uqVHfu0Zlu7FMyXzv+i1PqKtPQOv0sDAACjlFAgO4wlrQoc00Un1ipgOjRLNuNiacrZNIsFACALjCaQsaJ8DE0oK9QZ08fp3he2yDnntb+44GbpQKv0xLf8Lg8AAIxC3tGeNLN2DR+8TFJRSirCEV06d5I+/dvlWrmlTSdODkuTT5ZOerv09PekxrO9S5m9XVJv54Bjp9TbfWhs4ixpzuV+/yoAAGCAowYy51zZWBWCY7toTo0+/7sVuvfFLV4gk6Q3fF5a/QfpZ2+J74cEC6TjL5AKilNXKAAASMhRAxnSS2VJgc4+frz++OJWfeqimTIzqaJBev9fpbatUl6hlBcaeswPecd1S6Sfv03a+KR03Bv9/nUAAEAMgSzDXDp3km686wUt27RXCxoqvcHqOd7tWKac5c2QvfoIgQwAgDQymkX98MEFc6pVEAx4WyklqqBYajjDC2QAACBtEMgyTHkoX68/YYL++OJW9fWN4Iuu0xdJO1ZK7duSXxwAABgRAlkGWjyvVtvaOtW8YU/iJ08/zzsySwYAQNogkGWgN8yqVmFe4FCT2ERUn+RtTv4agQwAgHRBIMtApYV5WjRzov60fJuiiV62DAS8WbJXH5H6+lJTIAAASAiBLEMtnjdJu/Z16ZnXWhM/edp50v4d3loyAADgOwJZhjpvxkQVFwR170i+bdm/juyvyS0KAACMCIEsQxUVBPXGWdX684qt6okmeOmxfJI0YRYL+wEASBMEsgx26dxa7T3Qo7+t3ZX4ydPPkzY8KfV0JL8wAACQEAJZBjtnxgSVFeaNrEns9EVStMsLZQAAwFcEsgxWmBfU+XOq9ZeV29TVG03s5Clnetso0f4CAADfEcgy3OK5k9Te2avHX07wsmVBidRwOuvIAABIAwSyDHfWceNVWZyve/6+OfGTp50nbV8htW9PfmEAACBuGRnIzGyxmd0WiUT8LsV3BXkB/b8FdXpg1Ta17utK7OTpi7zja48mvS4AABC/jAxkzrl7nXPXhcNhv0tJC1curFdP1CU+S1YzVyoeRz8yAAB8lpGBDIPNqCnTgoYK/eq5TXIuga2UAgFp2rleIEvkPAAAkFQEsixx9cIGrd2xT0s37EnsxOmLvG2UtrONEgAAfiGQZYlL5taqpCCoXz23KbETp8W2UaL9BQAAviGQZYmSwjy9ef5k3ffiFrV19sR/YniyNH4G68gAAPARgSyLXLWwXp09ffrDsi2JnTh9UWwbpc7UFAYAAI6KQJZF5taFNau2XHcmetly+iKpt1Pa+FRqCgMAAEdFIMsiZqarFtZr+eaIVmxOoEdb41lSIJ/LlgAA+IRAlmUunz9ZhXmBxGbJ2EYJAABfEciyTLg4X286qVa/W7ZZHd0JbDg+/Txp+3Jp347UFQcAAIZFIMtCVy6sV3tnr/60fGv8J7GNEgAAviGQZaHTplZp6viSxC5b1syTiqpYRwYAgA8IZFnIzHTlwno9u3631u7YF99J/dsoPcI2SgAAjDECWZZ668l1yguYft2cwCzZ9EXSvm3SjtWpKwwAAAxBIMtSE8oK9cZZ1frN0hZ19/bFd9L02DZKXLYEAGBMEciy2JWn1qt1f7ceWr09vhPCddL4EwhkAACMMQJZFnv98RM0KRxKbMNxtlECAGDMEciyWDBguqKpXo+/slObdh+I76Tpi6TeDmnT06ktDgAA9COQZbm3L6yXJN21tCW+E6awjRIAAGONQJblJlcU6fXHT9BdzZsU7YujnUVhqVR/GtsoAQAwhvL8LgCpd/Wp9br+Z89rycs7dd7Micc+Yfp50l9vlu7/jHf5snt/7LZv8P2ufVLPAanhDOmCL0k1J6b+lwEAIAsRyHLAopnVGl9aoF89tzG+QDbzUunxb0rNt3sbjxeUSAWlh46l1YceB4LSi7+Wfvg6acG10nmfk8qqU/9LAQCQRQhkOaAgL6C3nlyn/3linXa0d2piWejoJ0ycKX1mi2QW3xuc+2lpyTekZ38orfitdPbHpDM+KOUXjb54AAByAGvIcsSVC+vV2+f0m6Wb4zsh3jAmScVV0kX/IX3wWW/7pb/eLP13k/TiXWzDBABAHAhkOWLahFKdOrVKdzVvkktVSBo3Xbrq59K77vNC2m/fJ/34jdLGZ1LzfgAAZAkCWQ65bP4kvbZrv16Jd8PxkZr6Oum6R6XLvidFWqTbL5Duere0Z31q3xcAgAxFIMsh58/yFts/sHJb6t8sEJQWXCN9eKl0zielNfd7lzH/+K9S29bUvz8AABmEQJZDJpaHNL++Qg+uinNvy2QoLJXO+4wXzBZcIy29Q7p1vtdSY9/OsasDAIA0lpGBzMwWm9ltkUjE71IyzgVzqvVCS0TbImO8V2V4srT429KHmqU5b5Ge+b707bnSQzdJB3aPbS0AAKSZjAxkzrl7nXPXhcNhv0vJOBfM9i5bPrh6DGfJBqqaKv2/73vfyJxxsfTEt6RvzZUe+Q+pk4ANAMhNGRnIMHLTJ5Rq6viSsb1sOZzxx0tvu1264Ulp+rnSY1/1gtmSb3g7AAAAkEMIZDnGzHTB7Go99eoutXX2+F2OVD1buvJn0nWPeXto/vVm71LmXz4rbX2RPmYAgJxAIMtB58+uVk/U6bE1abSoftJ86ZpfS+99yNsb85kfetsxfe8M6YlbvPYZAABkKQJZDlrQUKnxpQV6wO/LlsOpX+g1l73xZemSb0qhcm/h/y0nSndcKj3/f6w1AwBkHQJZDgoGTG+YWa1HX9qh7t4+v8sZXnGVtPB90nsfkD7yd2+/zLYt0h8+JH3jBK/R7Jo/S71dflcKAMCosbl4jjp/drXubN6kZ9a16nXHT/C7nKOrmiad+0npnE9Im5dKL94prfiNtPIeKVgo1c6T6hZKdU3eMVyX2F6cAAD4jECWo84+fryK8oN6YOX29A9kB5nFQleTdOF/SK/+VVr/uNTSLDX/j/T0d73XldYcCmd1C731aQUlvpYOAMDREMhyVCg/qNefMF4PrtquL142R5ZpM0rBfOmEC72bJEV7pO0rvHDW8px3e+k+7zkLShNnSxNnSRNnShNmefcrpkgBrtoDAPxHIMthF8yu0V9WbtfyzRHNravwu5zRCeZLkxZ4t1Pf743t3+Vd4mx5Ttryd2nDk9LyXx86J79YGn9CLKjNigW1mVK4nkueAIAxRSDLYYtmTlQwYHpw1fbMD2TDKRk/eBZN8r6huXONtGO1tPMl7/jqI9ILvzz0mlCFVDtXqpkr1c737o87ztswHQCAFCCQ5bDKkgI1TanUAyu3618vmOF3OWMjFJbqT/VuA3XskXa8JO1YKW1b7jWlffZHUjT2Lc78Yqn6RC+c1c7zwlpZreT6BtyisaPzjn2xx5IULJDyCrwvIfQfCwl5AABJBLKcd8GcGt183yptbD2ghnHFfpfjn6JKacoZ3u2gaI+062Vp6wteQNv6gvTCndJzP07e+1rQC2bBAu9YWObN0BVVxI6VA+4POAbypd4OqadzwDF26+k4dOzr9X5uXpGUP+CWFxpwv0jKD0mywQHzYKA8GDT7oofCZsK/p3k/X4cOhx4ncHl40M4Nh+3iMBabOnAlG8he42dIFfW+vT2BLMddMLtaN9+3Sg+s2qb3vW6a3+Wkl2C+VD3Hu81/hzfW1yftWeeFs449kgUG3wLBAY/NC1xyXrjr7fJm3Hq7vePhY72dUleb1LFXOtAqtb4qde71LrOOJATlhbzgFu2Sot1J/B8GALLQm75xaA2yDwhkOa6+qlgza8r0wKrtBLJ4BALSuOnebaz09Und7V5Q69jjhbS+3kMzWwOPeYWHZsAGzjz1Rb0Zs56O2Ixax9DHkhcgLeD9nhYY8Dg44PGA2a64uAEzW7HjwMfOJfgligGvHXJeKqew2FcVyGoVU3x9ewIZdMHsan3nkbXavb9bVSUFfpeDwwUC3tq3UFiqHOEfjEBQKiz1bgCAtEMTJuj82TXqc9LDq9Nwb0sAAHIAgQw6cXK5asMhPZiOm40DAJADCGSQmen82dVa8spOdXRH/S4HAICcQyCDJK9rf2dPn55Yu8vvUgAAyDkEMkiSTptWpbJQnh5ctc3vUgAAyDkEMkiS8oMBLZo5UQ+v3qFoH1/vBwBgLBHI0O/82dVq3d+t5zfu8bsUAAByCoEM/c45YYLyg6YHVnLZEgCAsUQgQ7+yUL7OnD5eD67aLue4bAkAwFghkGGQ82dXa33rAa3dsc/vUgAAyBkEMgxy/uxqSdIDNIkFAGDMEMgwSHV5SPPqKwhkAACMIQIZhrhgdrVe2LRX2yKdfpcCAEBOIJBhiItPrJEk/W7ZZp8rAQAgNxDIMMS0CaU6dWqVfvnsRvXRJBYAgJQjkGFY7zi1QRtaD+ip11r9LgUAgKxHIMOwLjqxRhXF+frFsxv9LgUAgKxHIMOwQvlBvfXkOj2wcpt27evyuxwAALIagQxHdPWpDeqJOt29tMXvUgAAyGoEMhzRcRNZ3A8AwFjIyEBmZovN7LZIJOJ3KVmPxf0AAKReRgYy59y9zrnrwuGw36VkPRb3AwCQehkZyDB2WNwPAEDqEchwTFefWs/ifgAAUohAhmM6bmIZi/sBAEghAhniwuJ+AABSh0CGuLC4HwCA1CGQIS4s7gcAIHUIZIgbi/sBAEgNAhnidnBx/69Y3A8AQFIRyJCQd5zaoPUs7gcAIKkIZEgIi/sBAEg+AhkSwuJ+AACSj0CGhLG4HwCA5CKQIWEs7gcAILkIZBgRFvcDAJA8BDKMCIv7AQBIHgIZRoTF/QAAJA+BDCN2cHH/r5s3+V0KAAAZjUCGETtuYpnOPm68bn9infZ39fpdDgAAGYtAhlH52PknaNe+bv30qfV+lwIAQMYikGFUTplSqUUzJ+qHj72mts4ev8sBACAjEcgwav9y/gmKdPTox4+v87sUAAAyEoEMo3bi5LDedFKNbn9inXbv7/a7HAAAMg6BDEnxsTeeoP3dvfrhklf9LgUAgIxDIENSHF9dpsvnT9ZPn1yvHe2dfpcDAEBGIZAhaf75DcerJ+r0vUeYJQMAIBEEMiRN4/gSvb2pTr94ZqM27+3wuxwAADIGgQxJ9aFFx0uSvvPXV3yuBACAzEEgQ1JNrijSO05r0K+bW7R+136/ywEAICMQyJB0Hzh3uvKDplsfZpYMAIB4EMiQdBPLQ3rXGY26Z9lmvbK93e9yAABIewQypMQ/nTNdJQV5uuWhl/0uBQCAtEcgQ0pUlRToPWdP1Z+Wb9OKzRG/ywEAIK0RyJAy7z17qsJF+brlQWbJAAA4GgIZUiZclK/rXj9ND7+0Q89v3ON3OQAApC0CGVLq3Wc2alxJgb75wBq/SwEAIG0RyJBSJYV5uuHc6frb2lY9+eouv8sBACAtEciQcteePkU15SF9/S9rFO1zfpcDAEDaIZAh5UL5QX38whn6+8a9NIsFAGAYBDKMibecPFlvO6VOt/71FT2yZoff5QAAkFYIZBgTZqabLztRM2vK9bE7l2nT7gN+lwQAQNogkGHMFBUE9f1rTla0z+kDP39enT1Rv0sCACAtEMgwphrHl+ibV8zT8s0RffG+VX6XAwBAWiCQYcxdMKdG158zXb94ZqPuXtridzkAAPiOQAZf3HjBCTp9WpU+e89yrdrS5nc5AAD4ikAGX+QFA/rvq09WuChfN/x8qSIdPX6XBACAbwhk8M2EskJ975qTtXlPh2686wU5R9NYAEBuIpDBV02NVfr0m2bpwVXb9cMlr/ldDgAAviCQwXfvOatRl5xUq6/d/5KeerXV73IAABhzBDL4zsz01bfNVeP4En34l89re1un3yUBADCmCGRIC6WFefrhtafoQHdUH/z58+qJ9vldEgAAY4ZAhrRxfHWZvvLWuWresEc30zQWAJBDMjKQmdliM7stEon4XQqS7M3zJun9r5uq/31qg3757Ea/ywEAYExkZCBzzt3rnLsuHA77XQpS4FMXz9LrT5igf/v9Cj23frff5QAAkHIZGciQ3YIB039ftUB1lcW6/v+WavPeDr9LAgAgpQhkSEvh4nz96J1N6u7t03X/26yO7qjfJQEAkDIEMqSt4yaW6ttXz9eqrW36+N108gcAZC8CGdLaopnV+viFM3Tfi1v1vUdf9bscAABSgkCGtHfDOdP15nmT9I0H1uihVdv9LgcAgKQjkCHtmZm++ta5mjOpXB+9c5le2d7ud0kAACQVgQwZoaggqNv+oUmh/KDe/7/Nihzo8bskAACShkCGjDGpokg/uPZkbd7boQ/98nn1sr0SACBLEMiQUZoaq/Sly0/U46/s0lf+/JLf5QAAkBR5fhcAJOrKhQ1ataVNP35inY6vLtWVCxv8LgkAgFEhkCEjfe7S2Xpt13596rfLFe2T3nEaoQwAkLm4ZImMlB8M6EfvbNJ5MybqM/cs14+WvOZ3SQAAjBiBDBkrlB/UD649RZfMrdWX/7Ratzz4Mt38AQAZiUuWyGgFeQHdetUCFecH9e2HX9H+rl599pJZMjO/SwMAIG4EMmS8YMBrHFtSmKcfP7FO+7t79aXLT1IwQCgDAGQGAhmyQiBg+sLi2SopDOq7j7yqA91RfeOKecoPclUeAJD+CGTIGmamj184UyWFefra/Wt0oDuq77xjgQrzgn6XBgDAUTF9gKzzgXOP0xcvm6MHV23X+37arAPdvX6XBADAURHIkJXeeUajvnHFPP1t7S6983+eVVsne18CANIXgQxZ622n1Ok77zhZL7Ts1Tt+9LR2tnf5XRIAAMMikCGrvemkWt32zia9umO/3vaDJ7V+136/SwIAYAgCGbLeeTMm6hfvP01tHT166/ef1Iste/0uCQCAQQhkyAkLGir1mxvOVFFBUFfd9rQeXbPD75IAAOhHIEPOmDahVL/9wJlqHFei9/20WXcvbfG7JAAAJBHIkGMmloV05z+drtOmVenGu17Qdx9Zy/6XAADfEciQc8pC+frJu0/VZfMn6et/WaOb/rBS0T5CGQDAP3TqR04qyAvolrfP18SyQv3o8XXaua9L//X2+Qrl09UfADD2CGTIWYGA6bOXzFZ1eUhf+uNq7dr3rH70ziaFi/L9Lg0AkGO4ZImc977XTdO3r5qvv2/coyt+8KTW7tjnd0kAgBxDIAMkXTZ/su74x1O1NdKpC7+1RF/4/Qrt2d/td1kAgBxBIANizjpuvB698VxdfWq9/u/pDTrn64/ox4+/pu7ePr9LAwBkOQIZMMC40kJ96fKTdP9HX6/5DZX60h9X64JbHtP9K7bRHgMAkDIEMmAYJ1SX6X/fc6ru+MeFyg8GdP3PlurqHz2tFZsjfpcGAMhCBDLgKM6dMVF//ufX6ebL5ujl7fu0+DtP6Ma7XtD2tk6/SwMAZBHL5MswTU1Nrrm52e8ykCMiHT367iNr9ZO/rVNeIKDLF0zSiZPDmjMprBnVZSoqoIcZAODIzGypc65p2OcIZEBiNrTu1zceeFmPrtmh9s5eSVLApOkTSjV7Urlm15ZrzqSwZk8qV1VJgc/VAgDSBYEMSAHnnFr2dGjlljat2tqmVVsiWrWlTVsihy5n1oZDmldXocsXTNKimdUqyGOVAADkqqMFMjr1AyNkZqqvKlZ9VbEuOrGmf3zP/u5YQPOC2pOv7tL9K7epqqRAl8+frCua6jSrttzHygEA6YYZMiDFon1Oj7+yU3c1t+jBVdvVHe3TiZPL9famer153iRVFHNZEwByAZcsgTSxZ3+3fr9ss+5a2qKVW9pUEAzogjnVuqKpXmcfN17BgPldIgAgRQhkQBpasTmiu5e26HfLNmvvgR7VhkO65KRaXXxSjRbUVypAOAOArEIgA9JYV29UD63aod8836LHX9mpnqjTxLJCXTinRhedWKPTplYpL8iXAQAg0xHIgAzR1tmjR17aoftXbNOja3aqoyeqiuJ8nT+rWhefVKOzjhuvwjz6nQFAJiKQARmoozuqx17eqb+s3KaHVm9Xe2evSgvztGjmRJ113Dg1jivRlHElmlhWyOVNAMgAtL0AMlBRQVAXnehdtuzu7dOTr+7SX1Zu0wMrt+sPL2zpf10oP6CGqmJNGVeixnHFaogdp1SVaFJFiMudAJABmCEDMky0z2nzng6tb92vDbsPaMOu2LF1vza0HlBXb1//a/MCptqKkOoqilVXWaS6yoPHItVVFaumPMQ3OwFgjDBDBmSRYMDUMK5YDeOKhzzX1+e0o72rP5xt2L1fm/d0qGVPhx5/ZZe2t3dq4L/BDga2yRVFKg/lK5QfVGFeQIX5AYXygirMD6gwL6hQ7FiYF1AoP6iCvID3uv7XHHr+4DkFeQHlBUx5AVMwYDIj+AHAkRDIgCwSCJhqwiHVhEM6bdq4Ic939Ua1ZW+nWvYcUMuejgHHDm3c7c2udfZE1dXbp66eqDp7+xTtS84sejAWzPIGHQMDApv3moCZAqbY0RQIeI+DAZNJksWO3t0B9w8fjz0afJD1P7ZBj3XY8wNfM9xzyUBIBdLHO0+fojfOrvbt/QlkQA4pzAtq6vgSTR1fEvc5vdG+QUGtsyeq7mifunq88a7eqLp6+ryx2P2D4719TtGo8459B499gx73RvvU57zZvT7nFHVSn3NyznvNwOf6nHQwHg5cbuGc5GLPOKf+WcCBY97j2H138NnBYXPg7OHhMTTe5R3xxtcMXi0CZKWeaN+xX5RCBDIAR5UXDCgvGFBJIX8uACBV+PoVAACAzwhkAAAAPiOQAQAA+IxABgAA4DMCGQAAgM8IZAAAAD4jkAEAAPiMQAYAAOAzAhkAAIDPCGQAAAA+I5ABAAD4jEAGAADgMwIZAACAzwhkAAAAPiOQAQAA+IxABgAA4DMCGQAAgM8IZAAAAD4z55zfNYyYme2UtCHFbzNe0q4UvwdGjs8nffHZpDc+n/TFZ5PeRvP5THHOTRjuiYwOZGPBzJqdc01+14Hh8fmkLz6b9Mbnk774bNJbqj4fLlkCAAD4jEAGAADgMwLZsd3mdwE4Kj6f9MVnk974fNIXn016S8nnwxoyAAAAnzFDBgAA4DMC2VGY2UVmtsbM1prZp/yuJ9eZ2e1mtsPMVgwYqzKzB83sldix0s8ac5WZ1ZvZI2a2ysxWmtk/x8b5fHxmZiEze9bMXoh9Nv8eG59qZs/E/r7daWYFfteay8wsaGZ/N7P7Yo/5fNKEma03s+VmtszMmmNjSf/bRiA7AjMLSvqupIslzZZ0tZnN9reqnHeHpIsOG/uUpIedc8dLejj2GGOvV9K/OudmSzpd0gdj/3/h8/Ffl6RFzrl5kuZLusjMTpf0VUm3OOeOk7RH0nv9KxGS/lnS6gGP+XzSy3nOufkD2l0k/W8bgezITpW01jn3mnOuW9KvJF3mc005zTm3RNLuw4Yvk/TT2P2fSrp8LGuCxzm31Tn3fOx+u7z/sEwWn4/vnGdf7GF+7OYkLZJ0d2ycz8ZHZlYn6RJJP449NvH5pLuk/20jkB3ZZEmbBjxuiY0hvVQ757bG7m+TVO1nMZDMrFHSAknPiM8nLcQuhy2TtEPSg5JelbTXOdcbewl/3/z1LUmfkNQXezxOfD7pxEl6wMyWmtl1sbGk/23LG+0PANKFc86ZGV8b9pGZlUr6jaSPOufavH/oe/h8/OOci0qab2YVku6RNNPfinCQmV0qaYdzbqmZnetzORje2c65zWY2UdKDZvbSwCeT9beNGbIj2yypfsDjutgY0st2M6uVpNhxh8/15Cwzy5cXxn7unPttbJjPJ4045/ZKekTSGZIqzOzgP8r5++afsyS92czWy1sas0jSt8Xnkzacc5tjxx3y/kFzqlLwt41AdmTPSTo+9k2XAklXSfqDzzVhqD9Ielfs/rsk/d7HWnJWbM3L/0ha7Zz7rwFP8fn4zMwmxGbGZGZFks6Xt8bvEUlvi72Mz8YnzrlPO+fqnHON8v4781fn3DXi80kLZlZiZmUH70u6QNIKpeBvG41hj8LM3iTv2n5Q0u3OuS/7W1FuM7NfSjpX0nhJ2yV9QdLvJP1aUoOkDZLe7pw7fOE/UszMzpb0uKTlOrQO5jPy1pHx+fjIzObKW3QclPeP8F87575oZtPkzchUSfq7pGudc13+VYrYJcsbnXOX8vmkh9jncE/sYZ6kXzjnvmxm45Tkv20EMgAAAJ9xyRIAAMBnBDIAAACfEcgAAAB8RiADAADwGYEMAADAZwQyAFnLzKJmtmzALWmbm5tZo5mtSNbPA5Db2DoJQDbrcM7N97sIADgWZsgA5BwzW29mXzOz5Wb2rJkdFxtvNLO/mtmLZvawmTXExqvN7B4zeyF2OzP2o4Jm9iMzW2lmD8Q64QNAwghkALJZ0WGXLK8c8FzEOXeSpO/I25FDkv5b0k+dc3Ml/VzSrbHxWyU95pybJ+lkSStj48dL+q5zbo6kvZLemtLfBkDWolM/gKxlZvucc6XDjK+XtMg591psU/RtzrlxZrZLUq1zric2vtU5N97MdkqqG7h1jZk1SnrQOXd87PEnJeU75740Br8agCzDDBmAXOWOcD8RA/cWjIp1uQBGiEAGIFddOeD4VOz+k5Kuit2/Rt6G6ZL0sKQbJMnMgmYWHqsiAeQG/jUHIJsVmdmyAY/vd84dbH1RaWYvypvlujo29mFJPzGzj0vaKekfY+P/LOk2M3uvvJmwGyRtTXXxAHIHa8gA5JzYGrIm59wuv2sBAIlLlgAAAL5jhgwAAMBnzJABAAD4jEAGAADgMwIZAACAzwhkAAAAPiOQAQAA+IxABgAA4LP/D+j7PW+2OAHoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "foldperf = {}\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
    "foldperf = {}\n",
    "# For fold results\n",
    "results = {}\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()    \n",
    "\n",
    "model_name = \"classifier\"\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(np.arange(len(dataset)))):\n",
    "    print(\"##############################################\")\n",
    "    print(\"Fold {}\".format(fold + 1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "    \n",
    "    # Classifier\n",
    "    model = Classifier(features_train[0].shape[0])\n",
    "    reset_weights(model)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    #lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=0, verbose=True)\n",
    "\n",
    "    history = {\"train_loss\": [], \"test_loss\": [], \"train_acc\": [], \"test_acc\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_correct = train_epoch(\n",
    "            model, device, train_loader, criterion, optimizer, lr_scheduler\n",
    "        )\n",
    "        test_loss, test_correct = valid_epoch(model, device, test_loader, criterion)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "        test_loss = test_loss / len(test_loader.sampler)\n",
    "        test_acc = test_correct / len(test_loader.sampler) * 100\n",
    "\n",
    "        lr_scheduler.step(test_loss)\n",
    "\n",
    "        print(\n",
    "            \"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(\n",
    "                epoch + 1, epochs, train_loss, test_loss, train_acc, test_acc\n",
    "            )\n",
    "        )\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"test_loss\"].append(test_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        if test_acc >= 90:\n",
    "            torch.save(model, f\"../experiment/{model_name}_fold_{fold}_epoch_{epoch}.pt\")\n",
    "            print(f\"save model at ../experiment/{model_name}_fold_{fold}_epoch_{epoch}.pt\")\n",
    "\n",
    "    foldperf[\"fold{}\".format(fold + 1)] = history\n",
    "\n",
    "    torch.save(model, f\"../experiment/{model_name}_fold_{fold}.pt\")\n",
    "    print(f\"save model at ../experiment/{model_name}_fold_{fold}.pt\")\n",
    "\n",
    "testl_f,tl_f,testa_f,ta_f=[],[],[],[]\n",
    "k=k_folds\n",
    "\n",
    "for fold, inner_dict in foldperf.items():\n",
    "    for key, value in inner_dict.items():\n",
    "        if key == \"train_acc\" or key == \"test_acc\":\n",
    "            new_list = [x.cpu() for x in inner_dict[key]]\n",
    "            inner_dict[key] = new_list\n",
    "\n",
    "for f in range(1,k+1):\n",
    "    tl_f.append(np.mean(foldperf['fold{}'.format(f)]['train_loss']))\n",
    "    testl_f.append(np.mean(foldperf['fold{}'.format(f)]['test_loss']))\n",
    "\n",
    "    ta_f.append(np.mean(foldperf['fold{}'.format(f)]['train_acc']))\n",
    "    testa_f.append(np.mean(foldperf['fold{}'.format(f)]['test_acc']))\n",
    "\n",
    "print('Performance of {} fold cross validation'.format(k))\n",
    "print(\"Average Training Loss: {:.3f} \\t Average Test Loss: {:.3f} \\t Average Training Acc: {:.2f} \\t Average Test Acc: {:.2f}\".format(np.mean(tl_f),np.mean(testl_f),np.mean(ta_f),np.mean(testa_f))) \n",
    "\n",
    "diz_ep = {'train_loss_ep':[],'test_loss_ep':[],'train_acc_ep':[],'test_acc_ep':[]}\n",
    "\n",
    "for i in range(epochs):\n",
    "    diz_ep['train_loss_ep'].append(np.mean([foldperf['fold{}'.format(f+1)]['train_loss'][i] for f in range(k)]))\n",
    "    diz_ep['test_loss_ep'].append(np.mean([foldperf['fold{}'.format(f+1)]['test_loss'][i] for f in range(k)]))\n",
    "    diz_ep['train_acc_ep'].append(np.mean([foldperf['fold{}'.format(f+1)]['train_acc'][i] for f in range(k)]))\n",
    "    diz_ep['test_acc_ep'].append(np.mean([foldperf['fold{}'.format(f+1)]['test_acc'][i] for f in range(k)]))\n",
    "\n",
    "# Plot losses\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.semilogy(diz_ep['train_loss_ep'], label='Train')\n",
    "plt.semilogy(diz_ep['test_loss_ep'], label='Test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.grid()\n",
    "plt.legend()\n",
    "plt.title('CNN loss')\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracies\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.semilogy(diz_ep['train_acc_ep'], label='Train')\n",
    "plt.semilogy(diz_ep['test_acc_ep'], label='Test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "#plt.grid()\n",
    "plt.legend()\n",
    "plt.title('CNN accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dfb52e9-d25a-4deb-894c-a6b55b9acc16",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_73335/668683560.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0667d6c7-edfd-4dc9-bb6a-dfaffd6b0fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (fc1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with Test Time Augmentation\n",
    "\n",
    "# Test features\n",
    "features_test = torch.load(os.path.join(load_dir, 'birds_features_test.pt'), map_location=torch.device(device))\n",
    "features_tensor = torch.stack([i for i in features_test])\n",
    "\n",
    "with open(\"../Global_embeddings/test_paths.txt\", \"r\") as file:\n",
    "    test_paths = file.read().split(\"\\n\")\n",
    "    \n",
    "#paths_tensor = torch.stack(test_paths)\n",
    "    \n",
    "#best_model_path = \"../experiment/model_k_fold_global_84.pth\"\n",
    "\n",
    "# Loading trained model\n",
    "#state_dict = torch.load(best_model_path)\n",
    "#model = Classifier(features_test[0].shape[0])\n",
    "#model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa2bdaa2-03e6-42f9-baf0-e548d86aac7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "517it [00:00, 3403.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully wrote ../experiment/model_k_fold_global_84_kaggle.csv, you can upload this file to the kaggle competition website\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_file = \"../experiment/model_k_fold_global_84_kaggle.csv\"\n",
    "\n",
    "with open(output_file, \"w\") as file:\n",
    "    file.write(\"Id,Category\\n\")\n",
    "    for path, embedding in tqdm(zip(test_paths, features_tensor)):\n",
    "        output = model(embedding)\n",
    "        pred = output.data.max(0, keepdim=True)[1]\n",
    "        file.write(\"%s,%d\\n\" % (path, pred))\n",
    "    print(\n",
    "        \"Succesfully wrote \"\n",
    "        + output_file\n",
    "        + \", you can upload this file to the kaggle competition website\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
