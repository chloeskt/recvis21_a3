{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37246bcb-1f11-43e4-af11-f04500ebee20",
   "metadata": {},
   "source": [
    "## Start model training:\n",
    "\n",
    "- Simple classifier that uses cropped images from detectron2\n",
    "- Even the images that are not cropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "166a5650-bc9f-4779-a154-e88f9ac9ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim \n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e36454a5-69a3-4c11-bd3b-9ce294ec240e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2644589f00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dir = '../embeddings'\n",
    "data = \"../cropped_bird_dataset\"\n",
    "#img_size = 299\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "weight_decay = 3e-4\n",
    "grad_clip = 5.\n",
    "seed = 1\n",
    "use_cuda = False\n",
    "experiment='../experiment'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6fb96d7-2580-4f0d-b7ab-8f83651c2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-layers network of the features\n",
    "\n",
    "# Features and labels\n",
    "features_train = torch.load(os.path.join(load_dir, \"birds_features_train.pt\"), map_location=torch.device(device))\n",
    "labels_train = torch.load(os.path.join(load_dir, \"birds_labels_train.pt\"), map_location=torch.device(device))\n",
    "\n",
    "features_val = torch.load(os.path.join(load_dir, \"birds_features_val.pt\"), map_location=torch.device(device))\n",
    "labels_val = torch.load(os.path.join(load_dir, \"birds_labels_val.pt\"), map_location=torch.device(device))\n",
    "\n",
    "# X = features.to(\"cpu\").numpy()\n",
    "\n",
    "# Dataloaders\n",
    "features_tensor = torch.stack([i for i in features_train])\n",
    "labels_tensor = torch.stack([i for i in labels_train])\n",
    "train_data = torch.utils.data.TensorDataset(features_tensor, labels_tensor) \n",
    "\n",
    "features_tensor = torch.stack([torch.Tensor(i) for i in features_val])\n",
    "labels_tensor = torch.stack([torch.Tensor([i]) for i in labels_val])\n",
    "val_data = torch.utils.data.TensorDataset(features_tensor,labels_tensor)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22ba24ef-92f4-4c28-a276-29434eee13bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self,embedding_dim):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(embedding_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Classifier(features_train[0].shape[0])\n",
    "\n",
    "if use_cuda:\n",
    "    print('Using GPU')\n",
    "    model.cuda()\n",
    "else:\n",
    "    print('Using CPU')\n",
    "\n",
    "# Optimizer, LR, and criterion\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training functions\n",
    "def train_classifier(model, train_loader, optimizer, lr_scheduler, criterion, epoch):\n",
    "    lr_scheduler.step()\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "              data, target = Variable(data.cuda()), Variable(target.cuda().long())\n",
    "        else:\n",
    "              data, target = Variable(data), Variable(target.long())\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #target = target.squeeze(1)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "\n",
    "def validation_classifier(model, criterion, val_loader):\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            if use_cuda:\n",
    "                data, target = Variable(data.cuda()), Variable(target.cuda().long())\n",
    "            else:\n",
    "                data, target = Variable(data), Variable(target.long())\n",
    "            output = model(data)\n",
    "            target = target.squeeze(1)\n",
    "            # sum up batch loss\n",
    "            validation_loss += criterion(output, target).data.item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        validation_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))\n",
    "    return(100. * correct / len(val_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204b891a-9e47-44c6-8676-63bf8b687bb9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1064 (0%)]\tLoss: 2.988859\n",
      "Train Epoch: 1 [320/1064 (29%)]\tLoss: 3.232284\n",
      "Train Epoch: 1 [640/1064 (59%)]\tLoss: 3.020114\n",
      "Train Epoch: 1 [960/1064 (88%)]\tLoss: 2.975322\n",
      "\n",
      "Validation set: Average loss: 0.1184, Accuracy: 11/100 (11%)\n",
      "Train Epoch: 2 [0/1064 (0%)]\tLoss: 2.994570\n",
      "Train Epoch: 2 [320/1064 (29%)]\tLoss: 2.935322\n",
      "Train Epoch: 2 [640/1064 (59%)]\tLoss: 2.967553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuxae/MVA/recvis21_a3/env/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [960/1064 (88%)]\tLoss: 2.949175\n",
      "\n",
      "Validation set: Average loss: 0.1169, Accuracy: 11/100 (11%)\n",
      "Train Epoch: 3 [0/1064 (0%)]\tLoss: 2.937651\n",
      "Train Epoch: 3 [320/1064 (29%)]\tLoss: 2.902635\n",
      "Train Epoch: 3 [640/1064 (59%)]\tLoss: 2.938890\n",
      "Train Epoch: 3 [960/1064 (88%)]\tLoss: 2.954123\n",
      "\n",
      "Validation set: Average loss: 0.1150, Accuracy: 25/100 (25%)\n",
      "Train Epoch: 4 [0/1064 (0%)]\tLoss: 2.954838\n",
      "Train Epoch: 4 [320/1064 (29%)]\tLoss: 2.942652\n",
      "Train Epoch: 4 [640/1064 (59%)]\tLoss: 2.939802\n",
      "Train Epoch: 4 [960/1064 (88%)]\tLoss: 2.916302\n",
      "\n",
      "Validation set: Average loss: 0.1062, Accuracy: 26/100 (26%)\n",
      "Train Epoch: 5 [0/1064 (0%)]\tLoss: 2.822976\n",
      "Train Epoch: 5 [320/1064 (29%)]\tLoss: 2.767088\n",
      "Train Epoch: 5 [640/1064 (59%)]\tLoss: 2.714249\n",
      "Train Epoch: 5 [960/1064 (88%)]\tLoss: 2.746144\n",
      "\n",
      "Validation set: Average loss: 0.1013, Accuracy: 40/100 (40%)\n",
      "Train Epoch: 6 [0/1064 (0%)]\tLoss: 2.649479\n",
      "Train Epoch: 6 [320/1064 (29%)]\tLoss: 2.708768\n",
      "Train Epoch: 6 [640/1064 (59%)]\tLoss: 2.831299\n",
      "Train Epoch: 6 [960/1064 (88%)]\tLoss: 2.611815\n",
      "\n",
      "Validation set: Average loss: 0.0970, Accuracy: 42/100 (42%)\n",
      "Train Epoch: 7 [0/1064 (0%)]\tLoss: 2.699769\n",
      "Train Epoch: 7 [320/1064 (29%)]\tLoss: 2.617126\n",
      "Train Epoch: 7 [640/1064 (59%)]\tLoss: 2.570072\n",
      "Train Epoch: 7 [960/1064 (88%)]\tLoss: 2.623519\n",
      "\n",
      "Validation set: Average loss: 0.0903, Accuracy: 50/100 (50%)\n",
      "Train Epoch: 8 [0/1064 (0%)]\tLoss: 2.455247\n",
      "Train Epoch: 8 [320/1064 (29%)]\tLoss: 2.717326\n",
      "Train Epoch: 8 [640/1064 (59%)]\tLoss: 2.637808\n",
      "Train Epoch: 8 [960/1064 (88%)]\tLoss: 2.453805\n",
      "\n",
      "Validation set: Average loss: 0.0867, Accuracy: 60/100 (60%)\n",
      "Train Epoch: 9 [0/1064 (0%)]\tLoss: 2.521954\n",
      "Train Epoch: 9 [320/1064 (29%)]\tLoss: 2.367049\n",
      "Train Epoch: 9 [640/1064 (59%)]\tLoss: 2.419221\n",
      "Train Epoch: 9 [960/1064 (88%)]\tLoss: 2.198271\n",
      "\n",
      "Validation set: Average loss: 0.0807, Accuracy: 49/100 (49%)\n",
      "Train Epoch: 10 [0/1064 (0%)]\tLoss: 2.192167\n",
      "Train Epoch: 10 [320/1064 (29%)]\tLoss: 2.368205\n",
      "Train Epoch: 10 [640/1064 (59%)]\tLoss: 2.028086\n",
      "Train Epoch: 10 [960/1064 (88%)]\tLoss: 2.137027\n",
      "\n",
      "Validation set: Average loss: 0.0753, Accuracy: 53/100 (53%)\n",
      "Train Epoch: 11 [0/1064 (0%)]\tLoss: 1.963402\n",
      "Train Epoch: 11 [320/1064 (29%)]\tLoss: 2.102111\n",
      "Train Epoch: 11 [640/1064 (59%)]\tLoss: 2.069899\n",
      "Train Epoch: 11 [960/1064 (88%)]\tLoss: 1.985454\n",
      "\n",
      "Validation set: Average loss: 0.0640, Accuracy: 60/100 (60%)\n",
      "Train Epoch: 12 [0/1064 (0%)]\tLoss: 1.577669\n",
      "Train Epoch: 12 [320/1064 (29%)]\tLoss: 1.665298\n",
      "Train Epoch: 12 [640/1064 (59%)]\tLoss: 1.936010\n",
      "Train Epoch: 12 [960/1064 (88%)]\tLoss: 2.043490\n",
      "\n",
      "Validation set: Average loss: 0.0698, Accuracy: 58/100 (58%)\n",
      "Train Epoch: 13 [0/1064 (0%)]\tLoss: 1.371105\n",
      "Train Epoch: 13 [320/1064 (29%)]\tLoss: 1.295294\n",
      "Train Epoch: 13 [640/1064 (59%)]\tLoss: 1.473000\n",
      "Train Epoch: 13 [960/1064 (88%)]\tLoss: 1.468271\n",
      "\n",
      "Validation set: Average loss: 0.0617, Accuracy: 60/100 (60%)\n",
      "Train Epoch: 14 [0/1064 (0%)]\tLoss: 1.584823\n",
      "Train Epoch: 14 [320/1064 (29%)]\tLoss: 1.091244\n",
      "Train Epoch: 14 [640/1064 (59%)]\tLoss: 1.056225\n",
      "Train Epoch: 14 [960/1064 (88%)]\tLoss: 1.428497\n",
      "\n",
      "Validation set: Average loss: 0.0596, Accuracy: 62/100 (62%)\n",
      "Train Epoch: 15 [0/1064 (0%)]\tLoss: 0.926821\n",
      "Train Epoch: 15 [320/1064 (29%)]\tLoss: 1.107151\n",
      "Train Epoch: 15 [640/1064 (59%)]\tLoss: 1.160153\n",
      "Train Epoch: 15 [960/1064 (88%)]\tLoss: 1.021428\n",
      "\n",
      "Validation set: Average loss: 0.0602, Accuracy: 65/100 (65%)\n",
      "Train Epoch: 16 [0/1064 (0%)]\tLoss: 0.898442\n",
      "Train Epoch: 16 [320/1064 (29%)]\tLoss: 0.882758\n",
      "Train Epoch: 16 [640/1064 (59%)]\tLoss: 0.791087\n",
      "Train Epoch: 16 [960/1064 (88%)]\tLoss: 1.144541\n",
      "\n",
      "Validation set: Average loss: 0.0594, Accuracy: 66/100 (66%)\n",
      "Train Epoch: 17 [0/1064 (0%)]\tLoss: 0.741047\n",
      "Train Epoch: 17 [320/1064 (29%)]\tLoss: 0.794017\n",
      "Train Epoch: 17 [640/1064 (59%)]\tLoss: 0.486994\n",
      "Train Epoch: 17 [960/1064 (88%)]\tLoss: 0.530772\n",
      "\n",
      "Validation set: Average loss: 0.0608, Accuracy: 65/100 (65%)\n",
      "Train Epoch: 18 [0/1064 (0%)]\tLoss: 0.610927\n",
      "Train Epoch: 18 [320/1064 (29%)]\tLoss: 0.501220\n",
      "Train Epoch: 18 [640/1064 (59%)]\tLoss: 0.605531\n",
      "Train Epoch: 18 [960/1064 (88%)]\tLoss: 0.476323\n",
      "\n",
      "Validation set: Average loss: 0.0580, Accuracy: 71/100 (71%)\n",
      "Saved model to ../experiment/model_18.pth. You can run `python evaluate.py --model ../experiment/model_18.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 19 [0/1064 (0%)]\tLoss: 0.507142\n",
      "Train Epoch: 19 [320/1064 (29%)]\tLoss: 0.389638\n",
      "Train Epoch: 19 [640/1064 (59%)]\tLoss: 0.316525\n",
      "Train Epoch: 19 [960/1064 (88%)]\tLoss: 0.421687\n",
      "\n",
      "Validation set: Average loss: 0.0544, Accuracy: 67/100 (67%)\n",
      "Train Epoch: 20 [0/1064 (0%)]\tLoss: 0.243649\n",
      "Train Epoch: 20 [320/1064 (29%)]\tLoss: 0.259956\n",
      "Train Epoch: 20 [640/1064 (59%)]\tLoss: 0.310742\n",
      "Train Epoch: 20 [960/1064 (88%)]\tLoss: 0.292962\n",
      "\n",
      "Validation set: Average loss: 0.0530, Accuracy: 65/100 (65%)\n",
      "Train Epoch: 21 [0/1064 (0%)]\tLoss: 0.266003\n",
      "Train Epoch: 21 [320/1064 (29%)]\tLoss: 0.276571\n",
      "Train Epoch: 21 [640/1064 (59%)]\tLoss: 0.247463\n",
      "Train Epoch: 21 [960/1064 (88%)]\tLoss: 0.239262\n",
      "\n",
      "Validation set: Average loss: 0.0529, Accuracy: 67/100 (67%)\n",
      "Train Epoch: 22 [0/1064 (0%)]\tLoss: 0.193837\n",
      "Train Epoch: 22 [320/1064 (29%)]\tLoss: 0.176826\n",
      "Train Epoch: 22 [640/1064 (59%)]\tLoss: 0.166139\n",
      "Train Epoch: 22 [960/1064 (88%)]\tLoss: 0.143566\n",
      "\n",
      "Validation set: Average loss: 0.0553, Accuracy: 67/100 (67%)\n",
      "Train Epoch: 23 [0/1064 (0%)]\tLoss: 0.166385\n",
      "Train Epoch: 23 [320/1064 (29%)]\tLoss: 0.180911\n",
      "Train Epoch: 23 [640/1064 (59%)]\tLoss: 0.169846\n",
      "Train Epoch: 23 [960/1064 (88%)]\tLoss: 0.145057\n",
      "\n",
      "Validation set: Average loss: 0.0531, Accuracy: 68/100 (68%)\n",
      "Saved model to ../experiment/model_23.pth. You can run `python evaluate.py --model ../experiment/model_23.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 24 [0/1064 (0%)]\tLoss: 0.132423\n",
      "Train Epoch: 24 [320/1064 (29%)]\tLoss: 0.113967\n",
      "Train Epoch: 24 [640/1064 (59%)]\tLoss: 0.121713\n",
      "Train Epoch: 24 [960/1064 (88%)]\tLoss: 0.118192\n",
      "\n",
      "Validation set: Average loss: 0.0580, Accuracy: 67/100 (67%)\n",
      "Train Epoch: 25 [0/1064 (0%)]\tLoss: 0.108946\n",
      "Train Epoch: 25 [320/1064 (29%)]\tLoss: 0.093679\n",
      "Train Epoch: 25 [640/1064 (59%)]\tLoss: 0.104915\n",
      "Train Epoch: 25 [960/1064 (88%)]\tLoss: 0.096371\n",
      "\n",
      "Validation set: Average loss: 0.0572, Accuracy: 66/100 (66%)\n",
      "Train Epoch: 26 [0/1064 (0%)]\tLoss: 0.085972\n",
      "Train Epoch: 26 [320/1064 (29%)]\tLoss: 0.075625\n",
      "Train Epoch: 26 [640/1064 (59%)]\tLoss: 0.097581\n",
      "Train Epoch: 26 [960/1064 (88%)]\tLoss: 0.077629\n",
      "\n",
      "Validation set: Average loss: 0.0559, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_26.pth. You can run `python evaluate.py --model ../experiment/model_26.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 27 [0/1064 (0%)]\tLoss: 0.077358\n",
      "Train Epoch: 27 [320/1064 (29%)]\tLoss: 0.085258\n",
      "Train Epoch: 27 [640/1064 (59%)]\tLoss: 0.099735\n",
      "Train Epoch: 27 [960/1064 (88%)]\tLoss: 0.072984\n",
      "\n",
      "Validation set: Average loss: 0.0554, Accuracy: 67/100 (67%)\n",
      "Train Epoch: 28 [0/1064 (0%)]\tLoss: 0.080571\n",
      "Train Epoch: 28 [320/1064 (29%)]\tLoss: 0.094395\n",
      "Train Epoch: 28 [640/1064 (59%)]\tLoss: 0.061319\n",
      "Train Epoch: 28 [960/1064 (88%)]\tLoss: 0.070988\n",
      "\n",
      "Validation set: Average loss: 0.0540, Accuracy: 67/100 (67%)\n",
      "Train Epoch: 29 [0/1064 (0%)]\tLoss: 0.071171\n",
      "Train Epoch: 29 [320/1064 (29%)]\tLoss: 0.082772\n",
      "Train Epoch: 29 [640/1064 (59%)]\tLoss: 0.076488\n",
      "Train Epoch: 29 [960/1064 (88%)]\tLoss: 0.079890\n",
      "\n",
      "Validation set: Average loss: 0.0556, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_29.pth. You can run `python evaluate.py --model ../experiment/model_29.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 30 [0/1064 (0%)]\tLoss: 0.072872\n",
      "Train Epoch: 30 [320/1064 (29%)]\tLoss: 0.078181\n",
      "Train Epoch: 30 [640/1064 (59%)]\tLoss: 0.067463\n",
      "Train Epoch: 30 [960/1064 (88%)]\tLoss: 0.056838\n",
      "\n",
      "Validation set: Average loss: 0.0541, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_30.pth. You can run `python evaluate.py --model ../experiment/model_30.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 31 [0/1064 (0%)]\tLoss: 0.057068\n",
      "Train Epoch: 31 [320/1064 (29%)]\tLoss: 0.057595\n",
      "Train Epoch: 31 [640/1064 (59%)]\tLoss: 0.070780\n",
      "Train Epoch: 31 [960/1064 (88%)]\tLoss: 0.072672\n",
      "\n",
      "Validation set: Average loss: 0.0547, Accuracy: 68/100 (68%)\n",
      "Saved model to ../experiment/model_31.pth. You can run `python evaluate.py --model ../experiment/model_31.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 32 [0/1064 (0%)]\tLoss: 0.055415\n",
      "Train Epoch: 32 [320/1064 (29%)]\tLoss: 0.060042\n",
      "Train Epoch: 32 [640/1064 (59%)]\tLoss: 0.065286\n",
      "Train Epoch: 32 [960/1064 (88%)]\tLoss: 0.060674\n",
      "\n",
      "Validation set: Average loss: 0.0546, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_32.pth. You can run `python evaluate.py --model ../experiment/model_32.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 33 [0/1064 (0%)]\tLoss: 0.065393\n",
      "Train Epoch: 33 [320/1064 (29%)]\tLoss: 0.055981\n",
      "Train Epoch: 33 [640/1064 (59%)]\tLoss: 0.062745\n",
      "Train Epoch: 33 [960/1064 (88%)]\tLoss: 0.056821\n",
      "\n",
      "Validation set: Average loss: 0.0555, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_33.pth. You can run `python evaluate.py --model ../experiment/model_33.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 34 [0/1064 (0%)]\tLoss: 0.056824\n",
      "Train Epoch: 34 [320/1064 (29%)]\tLoss: 0.060534\n",
      "Train Epoch: 34 [640/1064 (59%)]\tLoss: 0.058696\n",
      "Train Epoch: 34 [960/1064 (88%)]\tLoss: 0.056007\n",
      "\n",
      "Validation set: Average loss: 0.0542, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_34.pth. You can run `python evaluate.py --model ../experiment/model_34.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 35 [0/1064 (0%)]\tLoss: 0.044114\n",
      "Train Epoch: 35 [320/1064 (29%)]\tLoss: 0.050291\n",
      "Train Epoch: 35 [640/1064 (59%)]\tLoss: 0.057034\n",
      "Train Epoch: 35 [960/1064 (88%)]\tLoss: 0.050977\n",
      "\n",
      "Validation set: Average loss: 0.0547, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_35.pth. You can run `python evaluate.py --model ../experiment/model_35.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 36 [0/1064 (0%)]\tLoss: 0.048649\n",
      "Train Epoch: 36 [320/1064 (29%)]\tLoss: 0.051554\n",
      "Train Epoch: 36 [640/1064 (59%)]\tLoss: 0.050980\n",
      "Train Epoch: 36 [960/1064 (88%)]\tLoss: 0.063821\n",
      "\n",
      "Validation set: Average loss: 0.0544, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_36.pth. You can run `python evaluate.py --model ../experiment/model_36.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 37 [0/1064 (0%)]\tLoss: 0.053063\n",
      "Train Epoch: 37 [320/1064 (29%)]\tLoss: 0.051384\n",
      "Train Epoch: 37 [640/1064 (59%)]\tLoss: 0.050693\n",
      "Train Epoch: 37 [960/1064 (88%)]\tLoss: 0.063393\n",
      "\n",
      "Validation set: Average loss: 0.0551, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_37.pth. You can run `python evaluate.py --model ../experiment/model_37.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 38 [0/1064 (0%)]\tLoss: 0.057587\n",
      "Train Epoch: 38 [320/1064 (29%)]\tLoss: 0.045270\n",
      "Train Epoch: 38 [640/1064 (59%)]\tLoss: 0.039123\n",
      "Train Epoch: 38 [960/1064 (88%)]\tLoss: 0.044067\n",
      "\n",
      "Validation set: Average loss: 0.0545, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_38.pth. You can run `python evaluate.py --model ../experiment/model_38.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 39 [0/1064 (0%)]\tLoss: 0.044467\n",
      "Train Epoch: 39 [320/1064 (29%)]\tLoss: 0.044241\n",
      "Train Epoch: 39 [640/1064 (59%)]\tLoss: 0.056386\n",
      "Train Epoch: 39 [960/1064 (88%)]\tLoss: 0.053708\n",
      "\n",
      "Validation set: Average loss: 0.0546, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_39.pth. You can run `python evaluate.py --model ../experiment/model_39.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 40 [0/1064 (0%)]\tLoss: 0.057564\n",
      "Train Epoch: 40 [320/1064 (29%)]\tLoss: 0.037011\n",
      "Train Epoch: 40 [640/1064 (59%)]\tLoss: 0.043246\n",
      "Train Epoch: 40 [960/1064 (88%)]\tLoss: 0.046930\n",
      "\n",
      "Validation set: Average loss: 0.0546, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_40.pth. You can run `python evaluate.py --model ../experiment/model_40.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 41 [0/1064 (0%)]\tLoss: 0.051307\n",
      "Train Epoch: 41 [320/1064 (29%)]\tLoss: 0.044053\n",
      "Train Epoch: 41 [640/1064 (59%)]\tLoss: 0.049315\n",
      "Train Epoch: 41 [960/1064 (88%)]\tLoss: 0.052687\n",
      "\n",
      "Validation set: Average loss: 0.0547, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_41.pth. You can run `python evaluate.py --model ../experiment/model_41.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 42 [0/1064 (0%)]\tLoss: 0.045347\n",
      "Train Epoch: 42 [320/1064 (29%)]\tLoss: 0.046960\n",
      "Train Epoch: 42 [640/1064 (59%)]\tLoss: 0.043613\n",
      "Train Epoch: 42 [960/1064 (88%)]\tLoss: 0.047090\n",
      "\n",
      "Validation set: Average loss: 0.0548, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_42.pth. You can run `python evaluate.py --model ../experiment/model_42.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 43 [0/1064 (0%)]\tLoss: 0.046821\n",
      "Train Epoch: 43 [320/1064 (29%)]\tLoss: 0.049416\n",
      "Train Epoch: 43 [640/1064 (59%)]\tLoss: 0.047729\n",
      "Train Epoch: 43 [960/1064 (88%)]\tLoss: 0.043399\n",
      "\n",
      "Validation set: Average loss: 0.0548, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_43.pth. You can run `python evaluate.py --model ../experiment/model_43.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 44 [0/1064 (0%)]\tLoss: 0.046578\n",
      "Train Epoch: 44 [320/1064 (29%)]\tLoss: 0.044845\n",
      "Train Epoch: 44 [640/1064 (59%)]\tLoss: 0.058653\n",
      "Train Epoch: 44 [960/1064 (88%)]\tLoss: 0.048153\n",
      "\n",
      "Validation set: Average loss: 0.0548, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_44.pth. You can run `python evaluate.py --model ../experiment/model_44.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 45 [0/1064 (0%)]\tLoss: 0.047498\n",
      "Train Epoch: 45 [320/1064 (29%)]\tLoss: 0.053429\n",
      "Train Epoch: 45 [640/1064 (59%)]\tLoss: 0.045499\n",
      "Train Epoch: 45 [960/1064 (88%)]\tLoss: 0.047291\n",
      "\n",
      "Validation set: Average loss: 0.0548, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_45.pth. You can run `python evaluate.py --model ../experiment/model_45.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 46 [0/1064 (0%)]\tLoss: 0.051233\n",
      "Train Epoch: 46 [320/1064 (29%)]\tLoss: 0.042583\n",
      "Train Epoch: 46 [640/1064 (59%)]\tLoss: 0.041406\n",
      "Train Epoch: 46 [960/1064 (88%)]\tLoss: 0.038033\n",
      "\n",
      "Validation set: Average loss: 0.0548, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_46.pth. You can run `python evaluate.py --model ../experiment/model_46.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 47 [0/1064 (0%)]\tLoss: 0.044339\n",
      "Train Epoch: 47 [320/1064 (29%)]\tLoss: 0.047520\n",
      "Train Epoch: 47 [640/1064 (59%)]\tLoss: 0.047138\n",
      "Train Epoch: 47 [960/1064 (88%)]\tLoss: 0.050513\n",
      "\n",
      "Validation set: Average loss: 0.0548, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_47.pth. You can run `python evaluate.py --model ../experiment/model_47.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 48 [0/1064 (0%)]\tLoss: 0.050069\n",
      "Train Epoch: 48 [320/1064 (29%)]\tLoss: 0.043219\n",
      "Train Epoch: 48 [640/1064 (59%)]\tLoss: 0.046096\n",
      "Train Epoch: 48 [960/1064 (88%)]\tLoss: 0.044071\n",
      "\n",
      "Validation set: Average loss: 0.0548, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_48.pth. You can run `python evaluate.py --model ../experiment/model_48.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 49 [0/1064 (0%)]\tLoss: 0.044165\n",
      "Train Epoch: 49 [320/1064 (29%)]\tLoss: 0.046372\n",
      "Train Epoch: 49 [640/1064 (59%)]\tLoss: 0.041706\n",
      "Train Epoch: 49 [960/1064 (88%)]\tLoss: 0.050861\n",
      "\n",
      "Validation set: Average loss: 0.0548, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_49.pth. You can run `python evaluate.py --model ../experiment/model_49.pth` to generate the Kaggle formatted csv file\n",
      "\n",
      "Train Epoch: 50 [0/1064 (0%)]\tLoss: 0.039425\n",
      "Train Epoch: 50 [320/1064 (29%)]\tLoss: 0.044779\n",
      "Train Epoch: 50 [640/1064 (59%)]\tLoss: 0.042339\n",
      "Train Epoch: 50 [960/1064 (88%)]\tLoss: 0.045125\n",
      "\n",
      "Validation set: Average loss: 0.0548, Accuracy: 69/100 (69%)\n",
      "Saved model to ../experiment/model_50.pth. You can run `python evaluate.py --model ../experiment/model_50.pth` to generate the Kaggle formatted csv file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the classifier \n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_classifier(model, train_loader, optimizer, lr_scheduler, criterion, epoch)\n",
    "    val_acc=validation_classifier(model, criterion, val_loader)\n",
    "    if val_acc>=68:\n",
    "      # Save only when it is good enough\n",
    "        model_file = experiment + '/model_' + str(epoch) + '.pth'\n",
    "        torch.save(model.state_dict(), model_file)\n",
    "        print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0667d6c7-edfd-4dc9-bb6a-dfaffd6b0fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with Test Time Augmentation\n",
    "\n",
    "# Test features\n",
    "features_test = torch.load(os.path.join(load_dir, 'birds_features_train.pt'), map_location=torch.device(device))\n",
    "\n",
    "best_model_path = \"../experiment/model_18.pth\"\n",
    "\n",
    "# Loading trained model\n",
    "state_dict = torch.load(best_model_path)\n",
    "model = Classifier(features_test[0].shape[0])\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2bdaa2-03e6-42f9-baf0-e548d86aac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    print('Using GPU')\n",
    "    model.cuda()\n",
    "else:\n",
    "    print('Using CPU')\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, \"rb\") as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert(\"RGB\")\n",
    "\n",
    "output_file = \"../experiment/kaggle.csv\"\n",
    "\n",
    "output_file = open(outfile, \"w\")\n",
    "\n",
    "output_file.write(\"Id,Category\\n\")\n",
    "\n",
    "test_list=[]\n",
    "for line in open(os.path.join(args.data+ '/flip_bird_dataset/test.txt'), 'r'):\n",
    "    test_list.append(line[:-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902a3758-616e-45be-bc60-c4dd3f6caac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in tqdm(os.listdir(test_dir)):\n",
    "    if \"jpg\" in f:\n",
    "        data = data_transforms[\"test\"](pil_loader(test_dir + \"/\" + f))\n",
    "        data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "        output = model(data)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        output_file.write(\"%s,%d\\n\" % (f[:-4], pred))\n",
    "\n",
    "output_file.close()\n",
    "\n",
    "print(\n",
    "    \"Succesfully wrote \"\n",
    "    + args.outfile\n",
    "    + \", you can upload this file to the kaggle competition website\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
